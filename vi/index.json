[{"uri":"https://EroEroz.github.io/vi/","title":"Báo cáo thực tập","tags":[],"description":"","content":"Báo cáo thực tập Thông tin sinh viên: Họ và tên: Nguyễn Hoàng Gia Huy\nSố điện thoại: 0902566797\nEmail: huynhgse182631@fpt.edu.vn\nTrường: Đại học FPT\nNgành: Trí tuệ nhân tạo\nLớp: AWS First Cloud Journey\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 12/08/2025 đến ngày 12/11/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "},{"uri":"https://EroEroz.github.io/vi/3-blogstranslated/3.1-blog1/","title":"Blog 1","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "},{"uri":"https://EroEroz.github.io/vi/3-blogstranslated/3.2-blog2/","title":"Blog 2","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "},{"uri":"https://EroEroz.github.io/vi/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "},{"uri":"https://EroEroz.github.io/vi/3-blogstranslated/3.4-blog4/","title":"Blog 4","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "},{"uri":"https://EroEroz.github.io/vi/3-blogstranslated/3.5-blog5/","title":"Blog 5","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "},{"uri":"https://EroEroz.github.io/vi/3-blogstranslated/3.6-blog6/","title":"Blog 6","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "},{"uri":"https://EroEroz.github.io/vi/5-workshop/5.7-security/5.7.1-s3-cloudfront/","title":"Cấu hình S3 &amp; CloudFront","tags":[],"description":"","content":"1. Tạo S3 Bucket:\nTạo Bucket (VD: minimarket-assets-prod) Block Public Access: On Upload thủ công thư mục images từ code lên Bucket này 2. Tạo CloudFront Distribution:\nOrigin type: Chọn Elastic Load Balancer Origin Domain: Chọn Load Balancer của Beanstalk Settings: Chọn Customize origin settings Protocol: HTTP Only Cache settings: Chọn Customize cache settings Viewer Protocol Policy: Redirect HTTP to HTTPS 3. Thêm Origin S3 (Để lấy ảnh):\nVào Distribution mới tạo Vào tab Origins \u0026gt; Create Origin Origin domain chọn cái S3 đã được tạo lúc nãy (minimarket-assets-prod) Origin Access: Chọn Origin access control (OAC) \u0026gt; Create new OAC Bucket Policy: Copy policy do CloudFront cung cấp và dán vào S3 Bucket policy 4. Cấu hình Behavior:\nQuay lại CloudFront vào tab Behaviors Tạo Behavior với Path pattern: /images/ Trỏ về Origin S3 Cache Policy: CachingOptimized "},{"uri":"https://EroEroz.github.io/vi/5-workshop/5.9-cleanup/5.9.1-cleanup/","title":"Dọn dẹp tài nguyên","tags":[],"description":"","content":"Để tránh phát sinh chi phí không mong muốn sau khi hoàn thành Workshop, hãy xóa tài nguyên theo đúng thứ tự sau:\nNAT Gateway: Delete NAT Gateway \u0026gt; Đợi Deleted \u0026gt; Release Elastic IP (Quan trọng nhất vì tốn tiền nhất) Elastic Beanstalk: Terminate Environment ElastiCache: Delete Redis Cluster (Bỏ chọn Create Backup) RDS: Stop (hoặc Delete nếu không dùng nữa - nhớ bỏ chọn Final Snapshot). WAF: Manage resources \u0026gt; Disassociate \u0026gt; Delete protection pack (web ACL) S3: Empty và Delete Bucket (Có thể không xóa nếu còn sử dụng vì chi phí không tốn quá nhiều)\nCloudFront Disable và Delete\n"},{"uri":"https://EroEroz.github.io/vi/5-workshop/5.5-app/5.5.1-dockerize/","title":"Đóng gói với Docker","tags":[],"description":"","content":"Trước khi đưa lên Cloud, chúng ta cần đóng gói ứng dụng .NET Core thành một Docker Image\nTạo Dockerfile: Tại thư mục gốc của Solution, tạo file tên là Dockerfile (không có đuôi) ```dockerfile # GIAI ĐOẠN 1: BUILD FROM mcr.microsoft.com/dotnet/sdk:8.0 AS build WORKDIR /src COPY [\u0026quot;MiniMarket.sln\u0026quot;, \u0026quot;./\u0026quot;] COPY [\u0026quot;WebShop/WebShop.csproj\u0026quot;, \u0026quot;WebShop/\u0026quot;] # ... (Copy các project khác nếu có) RUN dotnet restore \u0026quot;MiniMarket.sln\u0026quot; COPY . . WORKDIR \u0026quot;/src/WebShop\u0026quot; RUN dotnet build \u0026quot;WebShop.csproj\u0026quot; -c Release -o /app/build RUN dotnet publish \u0026quot;WebShop.csproj\u0026quot; -c Release -o /app/publish # GIAI ĐOẠN 2: RUNTIME FROM mcr.microsoft.com/dotnet/aspnet:8.0 AS final COPY --from=build /app/publish . WORKDIR /app EXPOSE 8080 ENTRYPOINT [\u0026quot;dotnet\u0026quot;, \u0026quot;WebShop.dll\u0026quot;] ENV ASPNETCORE_URLS=http://+:8080 ENV ASPNETCORE_ENVIRONMENT=Development ``` Tạo buildspec.yml: Tạo file buildspec.yml để hướng dẫn AWS CodeBuild cách đóng gói và đẩy lên ECR ```yaml version: 0.2 phases: pre_build: commands: - echo Logging in to Amazon ECR... # --- CẤU HÌNH THÔNG TIN --- - AWS_DEFAULT_REGION=ap-southeast-1 # Thay Account ID của bạn vào dòng dưới: - AWS_ACCOUNT_ID= ACCOUNT ID CỦA BẠN - IMAGE_REPO_NAME=market-app - IMAGE_TAG=$(echo $CODEBUILD_RESOLVED_SOURCE_VERSION | cut -c 1-7) - REPOSITORY_URI=$AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME # --------------------------- - aws ecr get-login-password --region $AWS_DEFAULT_REGION | docker login --username AWS --password-stdin $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com build: commands: - echo Build started on `date` - echo Building the Docker image... - docker build -t $REPOSITORY_URI:latest . - docker tag $REPOSITORY_URI:latest $REPOSITORY_URI:$IMAGE_TAG post_build: commands: - echo Build completed on `date` - echo Pushing the Docker image... - docker push $REPOSITORY_URI:latest - docker push $REPOSITORY_URI:$IMAGE_TAG - echo Writing image definitions file... # Tự động tạo file cấu hình Dockerrun.aws.json cho Beanstalk # Map Port 80 (Host) vào 8080 (Container .NET) - printf '{\u0026quot;AWSEBDockerrunVersion\u0026quot;:\u0026quot;1\u0026quot;,\u0026quot;Image\u0026quot;:{\u0026quot;Name\u0026quot;:\u0026quot;%s\u0026quot;,\u0026quot;Update\u0026quot;:\u0026quot;true\u0026quot;},\u0026quot;Ports\u0026quot;:[{\u0026quot;ContainerPort\u0026quot;:8080,\u0026quot;HostPort\u0026quot;:80}]}' \u0026quot;$REPOSITORY_URI:$IMAGE_TAG\u0026quot; \u0026gt; Dockerrun.aws.json - cat Dockerrun.aws.json artifacts: files: - Dockerrun.aws.json ``` "},{"uri":"https://EroEroz.github.io/vi/4-eventparticipated/4.1-event1/","title":"Event 1","tags":[],"description":"","content":"Bài thu hoạch “AWS Cloud Day 2025” Mục Đích Của Sự Kiện Cập nhật xu hướng công nghệ đám mây trong các ngành công nghiệp trọng điểm (Tài chính, Ngân hàng). Hiểu rõ chiến lược dữ liệu hiện đại để phục vụ cho Generative AI. Nắm bắt các mô hình hiện đại hóa ứng dụng (Modernization) trên AWS. Nội Dung Nổi Bật Dịch vụ Tài chính (Financial Services) \u0026amp; Hiện đại hóa Phá bỏ rào cản (Dissolving boundaries): Xu hướng xóa bỏ khoảng cách giữa Business và IT trong các tổ chức tài chính. Công nghệ không chỉ là hỗ trợ mà là động lực kinh doanh. Modernization: Các ngân hàng và tổ chức thanh toán đang chuyển dịch mạnh mẽ sang Cloud để tăng độ linh hoạt và trải nghiệm khách hàng. Phân tích Dữ liệu \u0026amp; GenAI (Data Analytics) Data Strategy: Dữ liệu là nhiên liệu cho AI. Cần xây dựng chiến lược dữ liệu vững chắc trước khi áp dụng Generative AI. Integration: Tích hợp các Foundation Models vào quy trình phân tích dữ liệu để cải thiện hiệu quả ra quyết định. Xây dựng \u0026amp; Hiện đại hóa trên AWS Cloud-native Architectures: Chuyển đổi từ kiến trúc nguyên khối (Monolith) sang Microservices và Serverless. Workload Modernization: Các chiến lược di chuyển (Migrate) và tối ưu hóa các ứng dụng cũ lên nền tảng AWS hiện đại. Những Gì Học Được Tư duy hiện đại hóa: Hiểu rằng \u0026ldquo;lên mây\u0026rdquo; không chỉ là di chuyển máy chủ, mà là thay đổi kiến trúc sang Cloud-native để tận dụng tối đa khả năng mở rộng. Tầm quan trọng của Dữ liệu: Generative AI chỉ hiệu quả khi có nguồn dữ liệu sạch và được tổ chức tốt. Ứng Dụng Vào Công Việc Áp dụng tư duy Cloud-native vào dự án MiniMarket (sử dụng Docker, Managed Services như RDS/ElastiCache thay vì tự cài đặt trên EC2). Cân nhắc về chiến lược dữ liệu cho các tính năng mở rộng sau này (VD: Phân tích hành vi mua hàng). "},{"uri":"https://EroEroz.github.io/vi/5-workshop/5.8-monitoring/5.8.1-cloudwatch/","title":"Giám sát với CloudWatch","tags":[],"description":"","content":" Tạo SNS Topic:\nVào SNS \u0026gt; Topics \u0026gt; Create Topic Type: Standard Name: DevOps-Alerts Tạo Subscription\nCreate Subscription \u0026gt; Protocol: Email \u0026gt; Nhập email của bạn (Nhớ Confirm mail) Tạo Alarm CPU:\nVào CloudWatch \u0026gt; Alarms \u0026gt; Create alarm Select metric \u0026gt; EC2 \u0026gt; Per-Instance Metrics \u0026gt; Chọn InstanceID của Beanstalk \u0026gt; CPUUtilization Condition: CPUUtilization: Greater than 70% Notification: Chọn Topic DevOps-Alerts Create Alarm. "},{"uri":"https://EroEroz.github.io/vi/5-workshop/5.1-workshop-overview/","title":"Giới thiệu","tags":[],"description":"","content":"Giới thiệu MiniMarket là một ứng dụng thương mại điện tử được xây dựng trên nền tảng .NET Core, áp dụng kiến trúc 3-lớp (3-Tier Architecture) hiện đại. Mục tiêu của Workshop này là chuyển đổi ứng dụng từ môi trường On-premise lên hạ tầng đám mây AWS (Cloud Native Migration) đảm bảo các tiêu chí của AWS Well-Architected Framework: Bảo mật, Tin cậy, Hiệu năng cao và Tối ưu chi phí Tổng quan về workshop Kiến trúc giải pháp:\nCompute: Sử dụng AWS Elastic Beanstalk (nền tảng Docker) để đơn giản hóa việc triển khai, quản lý hạ tầng và Auto Scaling Database: Amazon RDS for SQL Server được triển khai trong Private Subnet để đảm bảo an toàn dữ liệu Caching: Amazon ElastiCache (Redis) giúp lưu trữ Session người dùng và giảm tải truy vấn cho Database, tăng tốc độ phản hồi Network \u0026amp; Security (Mạng \u0026amp; Bảo mật): VPC: Thiết kế theo mô hình Public/Private Subnet kết hợp NAT Gateway Bảo mật lớp ứng dụng: Sử dụng AWS WAF kết hợp Amazon CloudFront để chống tấn công Web và phân phối nội dung toàn cầu Storage: Amazon S3 dùng để lưu trữ và phục vụ các static assets (hình ảnh sản phẩm) với độ bền cao DevOps: Quy trình CI/CD tự động hóa hoàn toàn với AWS CodePipeline và CodeBuild Monitoring: Amazon CloudWatch để theo dõi sức khỏe hệ thống (CPU, Network) và gửi cảnh báo "},{"uri":"https://EroEroz.github.io/vi/5-workshop/5.3-network/5.3.1-create-vpc/","title":"Khởi tạo VPC &amp; Subnets","tags":[],"description":"","content":" Mở Amazon VPC console (Lưu ý: Hãy chọn region phù hợp với nhu cầu, ở đây nhóm sử dụng Region ap-southeast-1) Chọn Create VPC Cấu hình: Tên: MiniMarket-VPC IPv4 CIDR: 10.0.0.0/16 Tạo Subnets (Chia 2 AZ để đảm bảo High Availability): Public Subnets (2): 10.0.1.0/24 \u0026amp; 10.0.2.0/24 (Dùng cho Load Balancer \u0026amp; NAT) Private Subnets (2): 10.0.3.0/24 \u0026amp; 10.0.4.0/24 (Dùng cho App, DB, Redis) Nhấn Create VPC và đợi cho state chuyển sang Available là thành công "},{"uri":"https://EroEroz.github.io/vi/1-worklog/","title":"Nhật ký công việc","tags":[],"description":"","content":"Giới thiệu\nNhật ký công việc này ghi lại hành trình thực tập 12 tuần của mình, tập trung vào việc xây dựng kỹ năng điện toán đám mây với AWS và khám phá các công nghệ liên quan. Mỗi tuần, mình đều ghi lại các mục tiêu, nhiệm vụ và kết quả đạt được.\nTuần 1: Giới thiệu về Dịch vụ AWS và Thiết lập Môi trường Đám mây\nTuần 2: Xử lý sự cố tài khoản, Thông tin từ Cloud Day và Khởi động NLP\nTuần 3: Khôi phục tài khoản, Đẩy nhanh tiến độ NLP và Tổ chức nhóm\nTuần 4: Lên ý tưởng dự án, Lựa chọn Tech Stack và Hoàn thành khóa học NLP\nTuần 5: Ước tính chi phí, Thiết kế kiến trúc ban đầu và Tiếp tục NLP\nTuần 6: Thiết kế lại kiến trúc, AWS Workshops và Hiểu biết về DevSecOps\nTuần 7: Chuẩn bị kỳ thi AWS, Nghiên cứu giá và Tìm hiểu sâu NLP\nTuần 8: Ôn tập chuyên sâu và Hoàn thành kỳ thi giữa kỳ AWS\nTuần 9: Hoàn thiện đề xuất dự án và Lập kế hoạch kiến trúc giải pháp\nTuần 10: NLP nâng cao (Mô hình chuỗi) và Hoàn thành đề xuất\nTuần 11: Chuẩn bị di chuyển lên Cloud và Cấu hình Codebase\nTuần 12: Triển khai lên AWS Cloud, CI/CD Pipeline và Tối ưu hóa dịch vụ\n"},{"uri":"https://EroEroz.github.io/vi/5-workshop/5.6-cicd/5.6.1-codebuild/","title":"Tạo Build Project","tags":[],"description":"","content":" Truy cập CodeBuild \u0026gt; Create project\nProject name: MiniMarket-Build\nSource: Chọn GitHub (Kết nối tới Repo chứa code)\nEnvironment:\nEnvironment image: Managed Image Operating system: Amazon Linux Runtime: Standard Image: 5.0 Service role: New service role Privileged: Enable (Bắt buộc để chạy lệnh Docker build) Buildspec: Use a buildspec file\nBấm Create build project\nSau khi tạo xong, vào IAM Role của CodeBuild vừa tạo, cấp thêm quyền AmazonEC2ContainerRegistryPowerUser để nó có thể đẩy ảnh lên ECR\n"},{"uri":"https://EroEroz.github.io/vi/5-workshop/5.4-data/5.4.1-security-groups/","title":"Thiết lập Security Groups","tags":[],"description":"","content":" Truy cập EC2 \u0026gt; Security Groups \u0026gt; Create security group Nhóm 1: Web Server (sg-web-app) Description: Cho phép HTTP từ Internet Inbound Rules: Type: HTTP (80) | Source: 0.0.0.0/0 (Hoặc chỉ từ Load Balancer nếu muốn chặt chẽ hơn) Nhóm 2: Database (sg-db-sql) Description: Chỉ cho phép truy cập từ Web Server Inbound Rules: Type: MSSQL (1433) | Source: Custom \u0026gt; Chọn ID của sg-web-app Nhóm 3: Redis Cache (sg-redis-cache) Description: Chỉ cho phép truy cập từ Web Server Inbound Rules: Type: Custom TCP (6379) | Source: Custom \u0026gt; Chọn ID của sg-web-app "},{"uri":"https://EroEroz.github.io/vi/1-worklog/1.1-week1/","title":"Worklog tuần 1","tags":[],"description":"","content":"Mục tiêu tuần 1: Hòa nhập với cộng đồng First Cloud Journey (FCJ) và nắm rõ các quy định. Thiết lập tài khoản AWS Free Tier và môi trường phát triển. Nắm vững các danh mục dịch vụ AWS cơ bản (Compute, Storage, Networking, Database). Bắt đầu tìm hiểu kỹ thuật về VPC và các dịch vụ cốt lõi. Các nhiệm vụ thực hiện trong tuần này: Thứ Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 3 - Hòa nhập \u0026amp; Thiết lập tài khoản + Gặp gỡ các thành viên FCJ và xem lại quy định cộng đồng + Tạo tài khoản AWS Free Tier + Khám phá giao diện AWS Management Console và hoàn thành Module 1 09/09/2025 09/09/2025 https://policies.fcjuni.com/ 4 - Thiết lập Môi trường \u0026amp; VPC + Cài đặt các tiện ích mở rộng để xây dựng trang tài liệu (Hugo/Worklog) + Bắt đầu Module 2: Networking - Học các khái niệm về Virtual Private Cloud (VPC) - Xem lại các tính năng Bảo mật VPC (Security Groups/NACLs) 10/09/2025 10/09/2025 https://cloudjourney.awsstudygroup.com/ 5 - Xem Module 2 Lab 3 để có cái nhìn tổng quan về chủ đề + Thực hành lý thuyết các khái niệm mạng trước khi triển khai 11/09/2025 11/09/2025 https://cloudjourney.awsstudygroup.com/ 6 - Khám phá Dịch vụ (Thực hành) + Khởi chạy một EC2 Instance + Thử nghiệm các tính năng GenAI trong Amazon Bedrock Playground + Tạo một hàm thử nghiệm sử dụng AWS Lambda + Cấp phát một cơ sở dữ liệu thử nghiệm sử dụng Amazon RDS 12/09/2025 12/09/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 1: Đã tạo và cấu hình thành công Tài khoản AWS. Đã làm quen với AWS Management Console và điều hướng dịch vụ. Nắm vững bốn trụ cột dịch vụ cơ bản: Compute, Storage, Networking, và Database. Học được các chiến lược tối ưu hóa chi phí cơ bản cho các dự án đám mây. "},{"uri":"https://EroEroz.github.io/vi/1-worklog/1.2-week2/","title":"Worklog Tuần 2","tags":[],"description":"","content":"Mục tiêu Tuần 2: Có kinh nghiệm thực tế về việc tạo và kết nối mạng Amazon EC2. Quản lý bảo mật tài khoản AWS và quy trình xử lý sự cố. Nắm bắt thông tin chi tiết về ngành thông qua AWS Cloud Day 2025. Bắt đầu chương trình chuyên sâu về Xử lý Ngôn ngữ Tự nhiên (NLP) trên Coursera. Các nhiệm vụ thực hiện trong tuần này: Thứ Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Lab EC2 \u0026amp; Xử lý sự cố + Public EC2 instance: Đã tạo thành công và xác minh kết nối + Private EC2 instance: Tạo thất bại; tài khoản bị tạm khóa trong quá trình + Đã tạo ticket hỗ trợ với AWS và hủy các instance hiện có để tiết kiệm chi phí 09/15/2025 09/15/2025 https://000003.awsstudygroup.com/4-createec2server/4.2-connectec2/ https://www.youtube.com/watch?v=wWu67GyrUNY\u0026list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026index=42 3 - Xem video lab AWS Module 2 trong khi chờ phản hồi hỗ trợ từ AWS - Đăng ký khóa học trên Coursera: \u0026ldquo;Natural Language Processing with Classification and Vector Spaces\u0026rdquo; 09/16/2025 09/16/2025 https://www.youtube.com/watch?v=Oo2UpjL-exE\u0026list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026index=46 https://www.coursera.org/learn/classification-vector-spaces-in-nlp/home/module/1 4 - Kiểm tra trạng thái hỗ trợ AWS (Đang chờ phản hồi) - Tiếp tục xem lại tài liệu lab AWS - Tiến triển qua Tuần 1 của khóa học NLP 09/17/2025 09/17/2025 https://www.youtube.com/watch?v=Oo2UpjL-exE\u0026list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026index=46 https://www.coursera.org/learn/classification-vector-spaces-in-nlp/home/module/1 5 - Tham dự Cloud Day 2025: + Dịch vụ Tài chính: Cách AWS hỗ trợ các tổ chức tài chính; xóa bỏ ranh giới giữa kinh doanh/CNTT; hiện đại hóa trong thanh toán, ngân hàng v.v. + Phân tích Dữ liệu: Chiến lược dữ liệu + generative AI, tích hợp các foundation model, sử dụng dữ liệu để cải thiện hiệu quả AI. + Di chuyển, Hiện đại hóa và Xây dựng trên AWS: Kiến trúc Cloud-native, serverless/microservices, hiện đại hóa workload. 09/18/2025 09/18/2025 6 - Hoàn thành Tuần 1 khóa học NLP trên Coursera + Hoàn thành bài tập lập trình: Hồi quy Logistic cho Phân tích Cảm xúc Tweet 09/19/2025 09/19/2025 https://www.coursera.org/learn/classification-vector-spaces-in-nlp/programming/P4CTb/logistic-regression Thành tựu Tuần 2: Đã khởi chạy và kiểm thử thành công các public EC2 instance. Đã bắt đầu quy trình xử lý sự cố chính thức cho việc tài khoản AWS bị tạm khóa. Nắm bắt được những hiểu biết chiến lược về FinTech, GenAI, và Di chuyển lên Đám mây thông qua Cloud Day 2025. Hoàn thành Tuần 1 của khóa học NLP, áp dụng hồi quy logistic vào dữ liệu phân tích cảm xúc thực tế. "},{"uri":"https://EroEroz.github.io/vi/1-worklog/1.3-week3/","title":"Worklog tuần 3","tags":[],"description":"","content":"Mục tiêu tuần 3: Hoàn thành Tuần 2 và 3 của khóa học Coursera \u0026ldquo;Natural Language Processing with Classification and Vector Spaces\u0026rdquo;. Giải quyết tình trạng Tài khoản AWS (Khôi phục) để chuẩn bị cho các bài lab cloud. Thiết lập cấu trúc Trang web Tài liệu cho học kỳ. Chính thức thiết lập vai trò nhóm và quy trình phát triển. Các nhiệm vụ thực hiện trong tuần này: Thứ Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Bắt đầu Tuần 2 khóa học NLP trên Coursera - Theo dõi hướng dẫn từ Hỗ trợ AWS để khôi phục tài khoản - Xem lại video hướng dẫn lab cho các module sắp tới 22/09/2025 22/09/2025 https://www.coursera.org/learn/classification-vector-spaces-in-nlp/home/module/2 3 - Họp nhóm: Thảo luận sơ bộ về cấu trúc nhóm - Hoàn thành Tuần 2 khóa học NLP + Hoàn thành Module 2 Lab 10 và bài tập cuối cùng - Luyện tập các LeetCode 23/09/2025 23/09/2025 https://www.coursera.org/learn/classification-vector-spaces-in-nlp/programming/xDch8/naive-bayes 4 - Thiết lập Tài liệu + Nghiên cứu và tùy chỉnh cấu trúc trang web (Hugo/GitHub Pages) cho Worklog và Đề xuất 24/09/2025 24/09/2025 5 - Bắt đầu Tuần 3 khóa học NLP trên Coursera - Luyện tập 2 bài LeetCode 25/09/2025 25/09/2025 https://www.coursera.org/learn/classification-vector-spaces-in-nlp/home/module/3 6 - Hoàn thành Tuần 3 khóa học NLP trên Coursera - Họp nhóm: Phân công vai trò (DevOps, Backend, Frontend) và thống nhất công cụ giao tiếp 26/09/2025 26/09/2025 https://www.coursera.org/learn/classification-vector-spaces-in-nlp/programming/vbHXo/assignment-vector-space-models Kết quả đạt được tuần 3: Đẩy nhanh tiến độ bằng cách hoàn thành cả Tuần 2 và Tuần 3 của Khóa học NLP. Tùy chỉnh thành công Trang web Tài liệu để lưu trữ các tài liệu dự án. Tổ chức các cuộc họp nhóm quan trọng để thiết lập vai trò và quy trình giao tiếp. Giải quyết các vấn đề quản trị AWS và duy trì thực hành code. "},{"uri":"https://EroEroz.github.io/vi/1-worklog/1.4-week4/","title":"Worklog tuần 4","tags":[],"description":"","content":"Mục tiêu tuần 4: Hoàn thành tuần cuối cùng của khóa học Coursera \u0026ldquo;Natural Language Processing with Classification and Vector Spaces\u0026rdquo;. Thúc đẩy các phiên thảo luận nhóm để quyết định chủ đề dự án cuối cùng. Thiết lập môi trường phát triển cục bộ (SQL Server, .NET SDK) cho dự án sắp tới. Dịch tài liệu kỹ thuật về AWS Disaster Recovery. Các nhiệm vụ thực hiện trong tuần này: Thứ Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Hoàn thành các bài giảng tuần 4 của khóa học NLP (Classification and Vector Spaces) - Luyện tập 2 bài LeetCode để duy trì tư duy lập trình 29/09/2025 29/09/2025 https://www.coursera.org/learn/classification-vector-spaces-in-nlp/home/module/4 3 - Thảo luận Ý tưởng Dự án Nhóm + Gặp gỡ nhóm để thảo luận về các ý tưởng dự án tiềm năng (thương mại điện tử so với hệ thống quản lý) + Phân tích ưu và nhược điểm của các tech stack khác nhau - Hoàn thành bài tập lập trình cuối cùng cho khóa học NLP 30/09/2025 30/09/2025 https://www.coursera.org/learn/classification-vector-spaces-in-nlp/programming/qFU3R/word-translation 4 - Lựa chọn Tech Stack + Xác nhận quyết định sử dụng .NET Core cho backend và SQL Server cho cơ sở dữ liệu - Tiếp tục luyện tập LeetCode 01/10/2025 01/10/2025 5 - Thiết lập Cơ sở dữ liệu \u0026amp; Môi trường + Cài đặt SQL Server và SSMS trên máy cục bộ + Cấu hình chuỗi kết nối cục bộ và xác minh kết nối + Nghiên cứu các best practice về lược đồ cơ sở dữ liệu cho chủ đề thương mại điện tử tiềm năng 02/10/2025 02/10/2025 https://learn.microsoft.com/en-us/sql/sql-server/ 6 - Dịch bài blog \u0026ldquo;Cross-Region disaster recovery using AWS Elastic Disaster Recovery\u0026rdquo; - Xem lại và hoàn thiện các mục worklog tuần 4 03/10/2025 03/10/2025 https://aws.amazon.com/blogs/storage/cross-region-disaster-recovery-using-aws-elastic-disaster-recovery/ Kết quả đạt được tuần 4: Đã hoàn thành thành công khóa học Coursera \u0026ldquo;Natural Language Processing with Classification and Vector Spaces\u0026rdquo;. Chốt Chủ đề Dự án và Tech Stack (.NET/SQL) sau khi thảo luận nhóm. Thiết lập Môi trường Phát triển Cục bộ hoạt động tốt, sẵn sàng để code. Mở rộng kiến thức về cloud thông qua việc dịch các bài blog kỹ thuật về AWS Disaster Recovery. "},{"uri":"https://EroEroz.github.io/vi/1-worklog/1.5-week5/","title":"Worklog tuần 5","tags":[],"description":"","content":"Mục tiêu tuần 5: Bắt đầu và tiến triển khóa học Coursera \u0026ldquo;Natural Language Processing with Probabilistic Models\u0026rdquo;. Tiếp tục dịch blog kỹ thuật AWS để nâng cao kiến thức về cloud. Duy trì thói quen lập trình bằng cách giải các bài tập LeetCode. Soạn thảo các phần đầu của Đề xuất Dự án Nhóm (Tuyên bố vấn đề \u0026amp; Kiến trúc). Đảm bảo tất cả các bản dịch tuân thủ đúng hướng dẫn về định dạng và văn phong. Các nhiệm vụ thực hiện trong tuần này: Thứ Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Dịch bài blog \u0026ldquo;Introducing the Amazon Braket Learning Plan\u0026rdquo; + Chỉnh sửa bài blog dịch trước đó để phù hợp với định dạng và văn phong chuẩn 06/10/2025 06/10/2025 https://aws.amazon.com/blogs/quantum-computing/introducing-the-amazon-braket-learning-plan-and-digital-badge/ 3 - Hoàn thành bản dịch bài blog \u0026ldquo;Understanding and Remediating Cold Starts: An AWS Lambda Perspective\u0026rdquo; - Đăng ký khóa học Coursera \u0026ldquo;Natural Language Processing with Probabilistic Models\u0026rdquo; - Giải 1 bài thử thách LeetCode để luyện tập lập trình 07/10/2025 07/10/2025 https://aws.amazon.com/blogs/compute/understanding-and-remediating-cold-starts-an-aws-lambda-perspective/ 4 - Hoàn thành Tuần 1 của khóa học Coursera (NLP): + Hoàn thành các bài giảng, bài kiểm tra và bài tập cho module giới thiệu 08/10/2025 08/10/2025 https://www.coursera.org/learn/probabilistic-models-in-nlp 5 - Nghiên cứu các Dịch vụ AWS cho dự án (Lambda, S3, API Gateway, DynamoDB) - Ước tính chi phí vận hành sử dụng AWS Pricing Calculator - Soạn thảo các phần đề xuất ban đầu: Tóm tắt điều hành và Tuyên bố vấn đề 09/10/2025 09/10/2025 https://calculator.aws/#/ 6 - Thiết kế Sơ đồ Kiến trúc Hệ thống ban đầu cho dự án nhóm - Viết tài liệu chi tiết để giúp đồng đội hình dung quy trình làm việc và tương tác giữa các thành phần - Bắt đầu Tuần 2 của khóa học Coursera “Natural Language Processing with Probabilistic Models” 10/10/2025 10/10/2025 https://www.coursera.org/learn/probabilistic-models-in-nlp Kết quả đạt được tuần 5: Hoàn thành Tuần 1 khóa học NLP trên Coursera và bắt đầu Tuần 2. Nghiên cứu các dịch vụ AWS phù hợp và phân tích chi phí vận hành ước tính. Soạn thảo các phần đầu của đề xuất dự án: Tóm tắt điều hành và Tuyên bố vấn đề. Thiết kế Kiến trúc Hệ thống ban đầu và tài liệu hóa. Hoàn thành bản dịch cho các blog kỹ thuật AWS về Quantum Computing và Lambda Cold Starts. "},{"uri":"https://EroEroz.github.io/vi/1-worklog/1.6-week6/","title":"Worklog tuần 6","tags":[],"description":"","content":"Mục tiêu tuần 6: Hoàn thành Tuần 2 và Tuần 3 của khóa học Coursera “Natural Language Processing with Probabilistic Models”. Xem lại và tóm tắt các khái niệm chính từ các bài lab AWS trước đây liên quan đến kiến trúc serverless. Tiếp tục phát triển đề xuất dự án, tập trung vào việc triển khai kỹ thuật và giải thích kiến trúc. Phối hợp với các thành viên trong nhóm để tinh chỉnh kiến trúc hệ thống và đảm bảo tính tương thích của các dịch vụ. Các nhiệm vụ thực hiện trong tuần này: Thứ Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Tiếp tục Tuần 2 khóa học Coursera “Natural Language Processing with Probabilistic Models” - Xem lại các bài lab AWS trước để củng cố hiểu biết về các dịch vụ cốt lõi và quy trình làm việc 13/10/2025 13/10/2025 https://www.coursera.org/learn/probabilistic-models-in-nlp/home/module/2 3 - Tập trung và hoàn thành Tuần 2 của khóa học NLP trên Coursera - Chỉnh sửa và xuất bản trang worklog lên GitHub Pages 14/10/2025 14/10/2025 https://www.coursera.org/learn/probabilistic-models-in-nlp/programming/8POp8/part-of-speech-tagging 4 - Bắt đầu Tuần 3 của khóa học Coursera “Natural Language Processing with Probabilistic Models” 15/10/2025 15/10/2025 https://www.coursera.org/learn/probabilistic-models-in-nlp/home/module/3 5 - Tham gia workshop \u0026ldquo;Data Science On AWS\u0026rdquo;: + Khám phá các dịch vụ như Amazon Textract và Amazon Polly + Tìm hiểu về chuẩn bị dữ liệu với SageMaker Canvas và Processing + Xem hướng dẫn xây dựng mô hình trong SageMaker Studio - Ôn tập tài liệu cho kỳ thi giữa kỳ AWS sắp tới - Tham gia hội thảo trực tuyến \u0026ldquo;Reinventing DevSecOps with AWS Generative AI\u0026rdquo;: + Tìm hiểu về vai trò DevSecOps và tác động của AI + Xem demo Amazon Q về review code và phát hiện vấn đề bảo mật 16/10/2025 16/10/2025 https://qhdn-hcmuni.fpt.edu.vn/2025/10/13/workshop-data-science-on-aws-mo-khoa-suc-manh-du-lieu-cung-dien-toan-dam-may/ https://www.facebook.com/share/v/1BnNV19jPs/ 6 - Tiếp tục tiến độ Tuần 3 khóa học Coursera - Ôn tập tài liệu cho kỳ thi giữa kỳ AWS sắp tới - Thiết kế lại sơ đồ Kiến trúc Dự án 17/10/2025 17/10/2025 https://www.coursera.org/learn/probabilistic-models-in-nlp/home/module/3 Kết quả đạt được tuần 6: Đã hoàn thành Tuần 2 khóa học Coursera “Natural Language Processing with Probabilistic Models” Đạt được tiến bộ đáng kể trong Tuần 3 của khóa học Coursera Mở rộng kiến thức thông qua việc tham gia hai sự kiện: workshop \u0026ldquo;Data Science On AWS\u0026rdquo; và \u0026ldquo;Reinventing DevSecOps with AWS Generative AI\u0026rdquo; Thiết kế lại kiến trúc dự án để nâng cao hiệu quả hệ thống và tích hợp dịch vụ "},{"uri":"https://EroEroz.github.io/vi/1-worklog/1.7-week7/","title":"Worklog tuần 7","tags":[],"description":"","content":"Mục tiêu tuần 7: Nâng cao kiến thức về Xử lý Ngôn ngữ Tự nhiên (Mô hình Xác suất). Chuẩn bị cho kỳ thi giữa kỳ AWS sắp tới. Tinh chỉnh các thành phần đề xuất dự án: Kiến trúc và Ước tính Chi phí. Các nhiệm vụ thực hiện trong tuần này: Thứ Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Hoàn thành Tuần 3 khóa học Coursera “Natural Language Processing with Probabilistic Models” - Xem lại bản nháp cho Đề xuất Dự án - Tiếp tục luyện tập cho kỳ thi giữa kỳ AWS 20/10/2025 20/10/2025 https://www.coursera.org/learn/probabilistic-models-in-nlp/programming/7GrBn/autocomplete 3 - Bắt đầu Tuần 4 khóa học Coursera (NLP) - Điều chỉnh sơ đồ Kiến trúc Hệ thống cho dự án - Luyện tập các câu hỏi thử cho kỳ thi giữa kỳ AWS 21/10/2025 21/10/2025 https://www.coursera.org/learn/probabilistic-models-in-nlp/home/module/4 4 - Tiếp tục Tuần 4 khóa học Coursera (NLP) - Ôn tập trọng tâm các chủ đề kỳ thi giữa kỳ AWS 22/10/2025 22/10/2025 https://www.coursera.org/learn/probabilistic-models-in-nlp/home/module/4 5 - Đạt thêm tiến độ trong Tuần 4 khóa học NLP - Nghiên cứu Giá dịch vụ AWS (EC2, RDS) để hỗ trợ các quyết định kiến trúc - Xem lại tài liệu học tập cho kỳ thi sắp tới 23/10/2025 23/10/2025 https://www.coursera.org/learn/probabilistic-models-in-nlp/home/module/4 6 - Tổng hợp ghi chú cho kỳ thi giữa kỳ AWS - Hoàn tất các chỉnh sửa trong tuần cho Đề xuất Dự án 24/10/2025 24/10/2025 Kết quả đạt được tuần 7: Hoàn thành Tuần 3 và tiến triển qua Tuần 4 của Chương trình chuyên sâu NLP. "},{"uri":"https://EroEroz.github.io/vi/1-worklog/1.8-week8/","title":"Worklog tuần 8","tags":[],"description":"","content":"Mục tiêu tuần 8: Ôn tập chuyên sâu các dịch vụ AWS cốt lõi và các thực hành tốt nhất về kiến trúc. Xác định và củng cố các lỗ hổng kiến thức thông qua các bài thi thử. Hoàn thành thành công Kỳ thi giữa kỳ AWS. Các nhiệm vụ thực hiện trong tuần này: Thứ Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Tập trung ôn tập toàn diện cho kỳ thi giữa kỳ AWS + Xem lại các dịch vụ cốt lõi bao gồm các kiến thức cơ bản về EC2, S3, và IAM 27/10/2025 27/10/2025 3 - Tiếp tục luyện tập với các bài test thử để xác định các phần bị yếu + Hiểu sâu hơn về VPC Networking và Security Groups 28/10/2025 28/10/2025 4 - Thực hiện ôn tập chuyên sâu các chủ đề thi + Tập trung vào Shared Responsibility Model và Cloud Economics 29/10/2025 29/10/2025 5 - Tiến hành review tất cả tài liệu học tập + Tổng hợp ghi chú và kiểm tra mức độ sẵn sàng cho kỳ thi 30/10/2025 30/10/2025 6 - Hoàn thành Kỳ thi giữa kỳ AWS 31/10/2025 31/10/2025 Kết quả đạt được tuần 8: Hoàn thành nhiều phiên học tập trung bao phủ tất cả các module AWS cốt lõi. Củng cố kiến thức kỹ thuật về Networking, Compute, và Security. Đã tham dự thành công Kỳ thi giữa kỳ AWS. "},{"uri":"https://EroEroz.github.io/vi/1-worklog/1.9-week9/","title":"Worklog tuần 9","tags":[],"description":"","content":"Mục tiêu tuần 9: Hoàn thành bản nháp toàn diện đầu tiên của đề xuất dự án nhóm. Định nghĩa Cloud Solution Architecture và lộ trình kỹ thuật. Thực hiện lập kế hoạch tài nguyên bao gồm AWS Budget Estimation và phân tích rủi ro. Các nhiệm vụ thực hiện trong tuần này: Thứ Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Tinh chỉnh Problem Statement để phù hợp với phạm vi giải pháp kỹ thuật 03/11/2025 03/11/2025 3 - Vẽ lại sơ đồ System Architecture để bao gồm các thành phần cloud + Viết lại phần Solution Architecture chi tiết hóa hạ tầng AWS 04/11/2025 04/11/2025 4 - Viết chiến lược Technical Implementation (Stack \u0026amp; Deployment) + Xác định Timeline \u0026amp; Milestones cho giai đoạn phát triển 05/11/2025 05/11/2025 5 - Nghỉ (Khám sức khỏe) 06/11/2025 06/11/2025 6 - Tính toán Budget Estimation tập trung vào chi phí hạ tầng AWS + Phân tích rủi ro kỹ thuật và chiến lược giảm thiểu cho phần Risk Assessment 07/11/2025 07/11/2025 Kết quả đạt được tuần 9: Hoàn thành thành công bản nháp đầy đủ đầu tiên của đề xuất dự án. Tái thiết kế nền tảng kỹ thuật bằng cách định nghĩa Cloud Architecture. Soạn thảo các phần lập kế hoạch chính: Technical Implementation, Timeline, và Cloud Budgeting. Tinh chỉnh Problem Statement để làm rõ các thách thức kỹ thuật đang được giải quyết. "},{"uri":"https://EroEroz.github.io/vi/2-proposal/","title":"Bản đề xuất","tags":[],"description":"","content":"Chuyển đổi số cho Mini-market trên nền tảng đám mây AWS Giải pháp E-commerce .NET 3-tier áp dụng Repository và Unit of Work Pattern 1. Tóm tắt điều hành Bản đề xuất này trình bày một giải pháp end-to-end nhằm \u0026ldquo;Chuyển đổi số cho Mini-market trên nền tảng đám mây AWS\u0026rdquo;. Các mini-market truyền thống hiện đang đối mặt với ba thách thức lớn: (1) Quản lý kho thủ công (bằng Excel/sổ tay) gây thất thoát doanh thu và lãng phí nguồn lực; (2) Lệ thuộc 100% vào kênh bán offline, bỏ lỡ thị trường e-commerce đang phát triển và mất khả năng cạnh tranh; và (3) Quy trình vận hành chậm chạp (như tra giá thủ công), mang lại trải nghiệm khách hàng kém.\nGiải pháp của nhóm là xây dựng một nền tảng e-commerce và quản lý vận hành toàn diện. Về software architecture, nhóm sẽ sử dụng kiến trúc .NET 3-lớp (ASP.NET Core MVC, EF Core) kết hợp Repository Pattern và Unit of Work Pattern. Về infrastructure architecture được thiết kế theo AWS Well-Architected Framework, chạy trên AWS Elastic Beanstalk (cho backend .NET), Amazon RDS for SQL Server (cho database), và Amazon S3 (cho static assets). Hệ thống được tối ưu hiệu năng bằng CloudFront và ElastiCache, và bảo mật bằng WAF, VPC, và NAT Gateway. Quy trình triển khai được tự động hóa hoàn toàn bằng CI/CD pipeline tích hợp với GitHub.\nBusiness benefits là ngay lập tức, bao gồm tự động hóa quản lý kho (giảm thất thoát) và mở ra một kênh doanh thu online mới. Về investment, chi phí hạ tầng trong 12 tháng đầu tiên là gần như bằng 0 nhờ tận dụng AWS Free Tier (ví dụ: RDS Express Edition, EC2 t3.micro). Chi phí vận hành dài hạn (sau Free Tier) cũng rất thực tế, ước tính chỉ khoảng 138.06 USD/tháng cho toàn bộ hệ thống. Với investment ban đầu tối thiểu và khả năng giải quyết trực tiếp các vấn đề gây thất thoát doanh thu, ROI là rất cao và gần như tức thì.\nDự án được đề xuất triển khai trong 12 tuần, chia thành 4 phases (giai đoạn) chính: (1) Foundation \u0026amp; Architecture, (2) Core Feature Development, (3) AWS Integration \u0026amp; CI/CD, và (4) Finalization \u0026amp; Deployment. Kết quả mong đợi được đo lường bằng các success metrics cụ thể: giảm 90% sai sót kho vận, giảm 50% thời gian thanh toán, và đạt 20% doanh thu từ kênh online trong 6 tháng đầu. Giải pháp này không chỉ giải quyết các vấn đề trước mắt mà còn cung cấp cho mini-market một nền tảng scalable để đưa ra quyết định dựa trên dữ liệu trong tương lai.\n2. Tuyên bố vấn đề Vấn đề hiện tại\nCác doanh nghiệp bán lẻ nhỏ và vừa, đặc biệt là mô hình \u0026ldquo;mini-market\u0026rdquo; truyền thống tại Việt Nam, đang vận hành dựa trên các quy trình thủ công đã lỗi thời. Trong bối cảnh thị trường ngày càng số hóa, việc không áp dụng công nghệ vào môi trường làm việc đã tạo ra một số vấn đề, trực tiếp ảnh hưởng đến khả năng tồn tại và phát triển của họ.\nMột số vấn đề chính\nVấn đề về quản lý kho thủ công dẫn đến tính thiếu chính xác trong số liệu và lãng phí nguồn lực: Đa số mini-market hiện nay quản lý hàng nghìn mã sản phẩm (SKUs) bằng sổ sách hoặc file Excel. Việc nhập/xuất kho và kiểm kê cuối ngày hoàn toàn dựa vào việc đếm và nhập thủ công. Việc này có thể dẫn đến sai sót trong dữ liệu vì quy trình nhập tay rất dễ xảy ra nhầm lẫn, tiêu biểu như mã sản phẩm và số lượng, việc này gây ra chênh lệch lớn giữa dữ liệu \u0026ldquo;trên sổ\u0026rdquo; và \u0026ldquo;thực tế\u0026rdquo; trong kho. Việc kiểm hàng hóa thủ công như này cũng sẽ đòi hỏi nguồn lực cao khi mà nhân viên sẽ phải dành hàng giờ mỗi ngày để kiểm kê, đối chiếu và chỉnh sữa báo cáo, thay vì tập trung vào phần bán hàng hoặc chăm sóc khách hàng. Cuối cùng là thất thoát tài chính, khi mà dữ liệu không được nhập chính xác, chủ cửa hàng sẽ không thể kiểm soát được tình trạng của hàng hóa như là hàng hóa hết hạn, hàng hóa bị hư hỏng, hoặc là bị mất cắp, dẫn đến thất thoát 5-10% giá trị hàng tồn kho hàng tháng. Vấn đề lệ thuộc vào bán hàng offline, bỏ lỡ thị trường E-commerce: Thông thường các mini-market ở Việt Nam đa số sẽ phụ thuộc vào khách vãng lai(offline). Họ cũng bị giới hạn bởi vị trí địa lí (chỉ phục vụ trong khu vực) và tệp khách hàng quen thuộc. Các cửa hàng như này sẽ đứng ngoài thị trường E-commerce, bỏ lỡ tệp khách hàng trẻ vốn đã quen thuộc với việc mua sắm online. Họ sẽ không thể cạnh tranh về sự tiện lợi như là đặt hàng 24/7 hay là giao hàng tận nơi so với các chuỗi cửa hàng tiện lợi lớn như là Circle K hoặc 7-Eleven và các ứng dụng giao hàng như Grab và Shopee, dẫn đến mất nguy cơ mất khách hàng theo thời gian. Vấn đề về vận hành và trải nghiệm của khách hàng: Quy trình thanh toán và tra cứu thông tin ở các mini-market truyền thống thông thường sẽ rất chậm chạp. Khi khách hàng hỏi về giá, thông tin của sản phẩm, hoặc là chương trình khuyến mãi, nhân viên (đặc biệt là nhân viên mới) sẽ phải tra cứu thủ công trong sổ sách dẫn đến tốn thời gian. Việc bắt khách hàng phải chờ đợi lâu để tra cứu thông tin hoặc tính tiền sẽ tạo ra sự ức chế và thiếu chuyên nghiệp. Nhân viên sẽ mất quá nhiều thời gian cho các tác vụ đơn giản, dễ nhầm lẫn (như là đọc nhầm giá do chữ viết xấu), làm giảm số lượng khách hàng có thể phục vụ trong giờ cao điểm. 3. Kiến trúc giải pháp Kiến trúc được thiết kế để giải quyết các vấn đề đã nêu, bằng cách kết hợp kiến trúc phần mềm .NET 3-lớp (Tier-3) với các dịch vụ đám mây được quản lý (Managed Services) của AWS. Kiến trúc này tuân thủ các nguyên tắc của AWS Well-Architected Framework, đảm bảo tính bảo mật, hiệu năng cao, khả năng phục hồi lỗi và tối ưu chi phí.\nDịch vụ AWS sử dụng\nAWS Elastic Beanstalk: Dịch vụ PaaS (Platform as a Service) được chọn để triển khai ứng dụng .NET 3-lớp (gồm Lớp Presentation WebShop và Lớp Application Services). Beanstalk tự động hóa 100% việc quản lý hạ tầng, bao gồm tự động tạo Auto Scaling Group (ASG) để đảm bảo tính co giãn (Scalability) và tiết kiệm chi phí.\nAmazon RDS (SQL Server): Dịch vụ Cơ Sở Dữ Liệu (CSDL) (Managed Relational Database Service) để host Lớp Persistence. SQL Server được chọn vì ứng dụng .NET của nhóm đã được phát triển và tối ưu cho SQL Server. Việc sử dụng RDS for SQL Server cho phép di chuyển (migrate) ứng dụng lên AWS mà không cần thay đổi code ở Lớp Dữ liệu. RDS cũng sẽ tự động hóa các tác vụ phức tạp như sao lưu (backup) hàng ngày, vá lỗi (patching) và phục hồi khi có sự cố (failover). Về tính bảo mật thì RDS được đặt trong Private Subnet, không thể truy cập trực tiếp từ Internet, chỉ cho phép ứng dụng trên Beanstalk kết nối. Và về vấn đề tối ưu chi phí, để tối ưu chi phí trong giai đoạn đầu, chúng ta có thể bắt đầu với phiên bản SQL Server Express Edition trên RDS, phiên bản này nằm trong Free Tier của AWS.\nAmazon S3: Dịch vụ lưu trữ đối tượng (Object Storage). Dùng để lưu trữ các static assets như hình ảnh sản phẩm, file CSS, và JavaScript. S3 cung cấp chi phí cực rẻ và khả năng mở rộng vô hạn.\nAmazon CloudFront: Dịch vụ Content Delivery Network - CDN. CloudFront lưu đệm (cache) các file tĩnh từ S3 tại các máy chủ (Edge Locations) trên toàn cầu, giúp người dùng tải trang nhanh hơn đáng kể. Giúp giảm tải trực tiếp cho máy chủ Beanstalk, và giúp ứng dụng .NET tập trung xử lý logic.\nAmazon WAF và Route 53: WAF (Web Application Firewall) và Route 53 (Dịch vụ DNS). WAF được liên kết với CloudFront để chặn các cuộc tấn công web phổ biến (như SQL injection, XSS). Route 53 cung cấp tên miền cho người dùng.\nAmazon ElastiCache (Redis): Dịch vụ in-memory data stores. Giúp giảm tải tối đa cho CSDL RDS khi có các truy vấn lặp đi lặp lại (ví dụ: lấy danh sách sản phẩm trang chủ). Ứng dụng .NET sẽ cache các dữ liệu \u0026ldquo;nóng\u0026rdquo; này trên ElastiCache, giúp tăng tốc độ phản hồi. Tương tự như RDS, ElastiCache cũng được đặt trong Private Subnet để đảm bảo an toàn.\nNAT Gateway: Dịch vụ Network Address Translation. NAT sẽ cung cấp lối ra Internet an toàn cho các dịch vụ trong Private Subnet (như Elastic Beanstalk). Điều này cho phép máy chủ tải về các bản vá bảo mật mà không bị truy cập trực tiếp từ bên ngoài.\nAWS CodePipeline/CodeBuild: Dịch vụ tích hợp và triển khai liên tục (CI/CD). Các dịch vụ này được tích hợp với GitLab để tự động hóa quy trình: (1) CodeBuild build code .NET, (2) CodePipeline deploy phiên bản mới lên Elastic Beanstalk.\nLuồng dữ liệu\n[1]-[2] Người dùng truy cập tên miền (qua Route 53) và được điều hướng đến CloudFront. Amazon WAF sẽ lọc request này.\n[3] (Luồng Tĩnh) Nếu là file tĩnh (ảnh, css), CloudFront lấy trực tiếp từ Amazon S3.\n[4]-[6] (Luồng Động) Nếu là request động, CloudFront chuyển tiếp qua Internet Gateway đến Application Load Balancer, sau đó ALB gửi request vào Elastic Beanstalk.\n[7]-[8] Ứng dụng .NET (trên Beanstalk) sẽ kiểm tra ElastiCache trước, nếu không có sẽ truy vấn Amazon RDS.\n[9]-[10] Khi Elastic Beanstalk cần ra Internet (để tải bản vá), nó sẽ đi qua NAT Gateway rồi ra Internet Gateway.\n[11]-[14] (Luồng CI/CD) Khi Dev push code lên Github, CodePipeline và CodeBuild sẽ tự động build và triển khai (deploy) phiên bản mới lên Elastic Beanstalk.\n4. Triển khai kỹ thuật Các giai đoạn triển khai\nDự án sẽ được chia thành 4 giai đoạn chính, kéo dài trong 12 tuần để đảm bảo tiến độ và chất lượng:\nXây dựng nền móng kỹ thuật: Tập trung xây dựng nền móng kỹ thuật, bao gồm việc chốt mô hình dữ liệu cho các thực thể chính, thiết lập cấu trúc solution .NET 3-lớp (Domain, Application, Persistence, WebShop), khởi tạo repository trên Github, và tìm hiểu về các dịch vụ của AWS. (Tuần 1-4)\nXây dựng các tính năng cốt lõi: Hoàn thiện Lớp Persistence (Repositories, Unit of Work) và Lớp Application (Services) cho các nhiệm vụ chính như quản lý sản phẩm, người dùng và đơn hàng. Song song đó, Lớp WebShop (Controllers, Views) sẽ được xây dựng cho các luồng đăng nhập, giỏ hàng, thanh toán và bắt đầu viết Unit Test cho Services. (Tuần 5-8)\nChuẩn bị di chuyển lên Cloud: Nhóm thực hiện tái cấu trúc (Refactor) mã nguồn để tương thích với môi trường Cloud (chuyển đổi cấu hình sang Biến môi trường), viết các kịch bản build (buildspec.yml) và sẵn sàng cho quy trình CI/CD. (Tuần 9-11)\nTriển khai hạ tầng \u0026amp; Hoàn thiện: Nhóm thực hiện khởi tạo toàn bộ tài nguyên trên AWS (Elastic Beanstalk, RDS, ElastiCache, S3). Cấu hình các dịch vụ bảo mật và hiệu năng (CloudFront, WAF) và kích hoạt quy trình CI/CD tự động. Cuối cùng là thực hiện UAT và giám sát hệ thống qua CloudWatch. (Tuần 12)\nYêu cầu kỹ thuật\nBackend: ASP.NET Core MVC 9.0. ORM: Entity Framework Core. Database: MS SQL Server 2022 (Local) và Amazon RDS for SQL Server (Cloud). Frontend: Bootstrap 5, jQuery, và Bootstrap Icons. Cloud Platform (AWS): Elastic Beanstalk, RDS, S3, CloudFront, WAF, Route 53, ElastiCache, VPC, NAT Gateway, CodePipeline, CodeBuild. Source Control: Git. Tools: Visual Studio 2022, Docker Desktop. Phương pháp phát triển\nÁp dụng phương pháp Agile (Scrum-like) để linh hoạt điều chỉnh theo yêu cầu và đảm bảo tiến độ, bám sát 4 giai đoạn triển khai đã đề ra. Mọi công việc (features, bugs) sẽ được theo dõi và quản lý thông qua Kanban board, giúp nhóm dễ dàng nắm bắt tiến độ của từng tác vụ (ví dụ: To Do, In Progress, Done). Mọi code mới phải được review thông qua merge requests trên Github trước khi được merge vào nhánh main, đảm bảo chất lượng code nhất quán.\nChiến lược kiểm thử\nĐể đảm bảo chất lượng và tính ổn định, nhóm sẽ thực hiện 3 cấp độ kiểm thử. Đầu tiên là Unit Testing, tập trung 100% vào Lớp Application (ví dụ: ProductService, OrderService) bằng cách giả lập các repository để cách ly Business Logic, sử dụng các framework kiểm thử tiêu chuẩn của .NET. Cấp độ thứ hai là Integration Testing, thực hiện trên môi trường Staging (trên Elastic Beanstalk) để kiểm tra sự tương tác giữa Lớp Application và Lớp Persistence (EF Core) với CSDL Amazon RDS thật. Cuối cùng, User Acceptance Testing sẽ được thực hiện trên môi trường Production để nhóm kiểm tra các luồng chức năng hoàn chỉnh trên giao diện người dùng như \u0026ldquo;Đăng ký, Đăng nhập, Thanh toán\u0026rdquo;.\nKế hoạch triển khai\nÁp dụng quy trình CI/CD tự động hóa hoàn toàn. Quy trình được kích hoạt tự động mỗi khi Dev push code lên Github. Github sẽ gửi webhook kích hoạt AWS CodePipeline, dịch vụ này sẽ lấy code và ra lệnh cho AWS CodeBuild thực hiện biên dịch dự án .NET, chạy Unit Test, và đóng gói ứng dụng thành file .zip. Nếu CodeBuild thành công, CodePipeline sẽ lấy file .zip và tự động triển khai phiên bản mới này lên môi trường Staging trên Elastic Beanstalk.\n5. Lộ trình \u0026amp; Mốc triển khai Dự án được lên kế hoạch thực hiện trong 12 tuần, chia thành 4 giai đoạn chính. Tiến độ này đảm bảo thời gian cho việc phát triển, integration, và testing kỹ lưỡng.\nPhase 1 (Tuần 1 - 4): Giai đoạn này tập trung xây dựng nền tảng kỹ thuật, bao gồm việc chốt data models, thiết lập Solution Architecture .NET 3-lớp, khởi tạo Github Repository, và tìm hiểu về các dịch vụ AWS. Milestone của giai đoạn này là Solution Architecture và Repository được thiết lập, cùng với môi trường AWS (VPC, Subnets).\nPhase 2 (Tuần 5 - 8): Sau khi Phase 1 hoàn thành, nhóm sẽ xây dựng các core features, hoàn thiện Lớp Persistence và Application (Quản lý Sản phẩm, Đơn hàng) và các feature flows cơ bản trên WebShop (Auth, Giỏ hàng). Milestone là các feature flows chính (Đăng nhập, Xem sản phẩm, Giỏ hàng, Thanh toán) hoạt động ổn định trên local, và Unit Test cho Services.\nPhase 3 (Tuần 9 - 11): Giai đoạn này chuẩn bị cho việc lên mây. Nhóm thực hiện tối ưu hóa mã nguồn (Refactoring), cấu hình Biến môi trường (Environment Variables), viết kịch bản tự động hóa (Buildspec) và dọn dẹp project để sẵn sàng cho quy trình CI/CD.\nPhase 4 (Tuần 12): Giai đoạn cuối cùng này tập trung vào hoàn thiện và triển khai, phụ thuộc vào bản build Staging ổn định từ Phase 3. Nhóm sẽ cấu hình các dịch vụ bảo mật (CloudFront, WAF, Route 53). Milestone là Version 1.0 được triển khai thành công lên Production environment (Elastic Beanstalk), User Acceptance Testing cuối cùng hoàn tất, và hệ thống được monitoring qua CloudWatch.\n6. Ước tính ngân sách Có thể xem chi phí trên AWS Pricing Calculator\nHoặc tải tệp ước tính ngân sách.\nChi phí hạ tầng\nBản ước tính từ AWS Pricing Calculator cho thấy chi phí vận hành hàng tháng của architecture này là 138.06 USD, với chi phí trả trước là 0.00 USD. Chiến lược tối ưu chi phí của nhóm tập trung vào việc tận dụng tối đa AWS Free Tier và các managed services. Con số 138.06 USD/tháng là một chi phí thực tế cho việc vận hành dài hạn (sau 12 tháng) một hệ thống e-commerce hoàn chỉnh, có khả năng scale và bảo mật cao.\nChi phí cho Elastic Beanstalk được chia nhỏ thành các resources mà nó quản lý: Amazon EC2 (1 instance t3a.small) với chi phí 19.15 USD/tháng và Elastic Load Balancing (1 Application Load Balancer) với chi phí 18.69 USD/tháng. Dịch vụ Amazon VPC có chi phí 46.02 USD/tháng, đây là chi phí cho 1 NAT Gateway, một thành phần bắt buộc cho thiết kế bảo mật Private Subnet của Elastic Beanstalk. Về database và cache, Amazon RDS for SQL Server (phiên bản Express Edition trên db.t3.micro) có chi phí 25.86 USD/tháng, và Amazon ElastiCache (cache.t4g.micro) là 17.52 USD/tháng. Các dịch vụ bảo mật và CI/CD như WAF (7.20 USD/tháng), CloudFront (2.43 USD/tháng), Route 53 (0.90 USD/tháng), S3 (0.17 USD/tháng), và CodeBuild (0.12 USD/tháng) chiếm phần chi phí còn lại.\nChiến lược tối ưu chi phí quan trọng nhất là tận dụng AWS Free Tier trong 12 tháng đầu. Mặc dù tổng ước tính là 138.06 USD/tháng, nhiều services cốt lõi trong đây (bao gồm EC2 t3a.small, RDS db.t3.micro, ElastiCache t4g.micro, S3, và CloudFront) đều nằm trong Free tier miễn phí 12 tháng. Do đó, chi phí vận hành thực tế trong năm đầu tiên sẽ thấp hơn đáng kể, chủ yếu chỉ bao gồm chi phí cho NAT Gateway (46.02 USD) và WAF (7.20 USD).\nVề phần tính toán ROI, và đầu tư lúc ban đầu gần như bằng 0 (do chi phí hạ tầng được nằm trong Free Tier và development costs là công sức của nhóm trong kỳ thực tập). Phần lợi nhuận gần như là ngay lập tức, vì giải pháp giải quyết trực tiếp các vấn đề thất thoát doanh thu (từ quản lý kho thủ công) và bỏ lỡ thị trường (do chỉ bán offline) đã nêu trong Problem Statement (Phần 1). Do đó, ROI (lợi tức đầu tư) là rất cao.\n7. Đánh giá rủi ro Một số rủi ro tiềm ẩn nằm trong ba lĩnh vực: Technical, Business, và Operational. Vậy nên một kế hoạch giảm thiểu và kế hoạch dự phòng đã được chuẩn bị cho các rủi ro có tác động cao.\nTechnical: Quá tải Hệ thống (Performance Bottleneck):\nImpact: High | Probability: Medium Đây là rủi ro hệ thống bị chậm hoặc sập khi có lượng traffic cao. Chiến lược giảm thiểu của nhóm là sử dụng ElastiCache để giảm tải query cho RDS, cấu hình Auto Scaling (trong Elastic Beanstalk) với các trigger hợp lý (ví dụ: CPU \u0026gt; 70%), và dùng CloudFront để cache file tĩnh. Kế hoạch dự phòng là sử dụng CloudWatch Alarms để cảnh báo ngay lập tức, và nếu RDS quá tải, nhóm sẽ thực hiện vertical scaling instance của RDS ngay lập tức. Business: Người dùng không chấp nhận (Low User Adoption):\nImpact: High | Probability: Medium Đây là rủi ro các chủ mini-market thấy giải pháp quá phức tạp và không sử dụng. Để giảm thiểu rủi ro này, nhóm sẽ bám sát thiết kế frontend (Bootstrap) đơn giản, thu thập feedback của chủ tiệm sớm từ Phase 2, và cung cấp tài liệu hướng dẫn. Kế hoạch dự phòng là nếu adoption thấp sau khi deploy, nhóm sẽ thực hiện một Sprint bổ sung (Phase 5) để ưu tiên điều chỉnh các features dựa trên feedback thu được. Operational: Mất hoặc rò rỉ dữ liệu (Data Loss / Breach):\nImpact: Critical | Probability: Low Chiến lược giảm thiểu của nhóm là cấu hình RDS tự động backup hàng ngày, đặt RDS và Beanstalk trong Private Subnet, sử dụng WAF để chặn tấn công, và quản lý connection string qua environment variables của Beanstalk. Kế hoạch dự phòng là nếu mất dữ liệu, nhóm sẽ thực hiện Point-in-Time Recovery (PITR) ngay lập tức từ backup của RDS. 8. Kết quả kỳ vọng Mục tiêu của giải pháp này là giải quyết trực tiếp các vấn đề đã nêu trong phần Tuyên bố vấn đề. Về business metrics, nhóm kỳ vọng giảm 90% sai sót trong quản lý kho (so với Excel/sổ tay), giảm 50% thời gian thanh toán tại quầy, và đạt được ít nhất 20% doanh thu mới từ kênh online trong 6 tháng đầu. Về technical metrics, mục tiêu là duy trì uptime (thời gian hoạt động) 99.9%, đảm bảo page load time (thời gian tải trang) trung bình dưới 2 giây (nhờ CloudFront và ElastiCache), và deployment frequency (tần suất triển khai) ổn định qua CI/CD pipeline.\nCác benefits được kỳ vọng là sẽ gia tăng theo thời gian. Trong short-term (0-6 tháng), chủ mini-market sẽ thấy trải nghiệm người dùng được cải thiện ngay lập tức và phần vận hành được cải thiện đáng kể (quản lý kho tự động). Trong medium-term (6-18 tháng), giá trị đến từ việc mở rộng thị trường (tiếp cận khách hàng online) và bắt đầu thu thập được business data có giá trị. Long-term value và strategic capabilities thu được chính là khả năng đưa ra quyết định dựa trên dữ liệu (data-driven decisions) (ví dụ: biết sản phẩm nào bán chạy) và khả năng scale hệ thống dễ dàng (thêm nhiều cửa hàng mới) nhờ Solution Architecture trên Elastic Beanstalk và RDS.\n"},{"uri":"https://EroEroz.github.io/vi/5-workshop/5.2-prerequiste/","title":"Các bước chuẩn bị","tags":[],"description":"","content":"IAM permissions Gắn quyền AdministratorAccess trong IAM permission policy vào tài khoản AWS để dễ dàng làm việc hơn Lưu ý: Việc sử dụng quyền Administrator chỉ được khuyến nghị cho môi trường Workshop để đảm bảo quá trình triển khai không bị gián đoạn. Trong môi trường Production thực tế, cần tuân thủ nguyên tắc Least Privilege cho từng dịch vụ { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Source Code Repository GitHub chứa code .NET Core và Dockerfile hợp lệ "},{"uri":"https://EroEroz.github.io/vi/5-workshop/5.3-network/5.3.2-gateways/","title":"Cấu hình Internet &amp; NAT Gateway","tags":[],"description":"","content":"Tạo Internet Gateway Trong phần VPC dashboard nhấn vào Internet gateways Sau đó nhấn vào Create internet gateway Trong phần tạo Internet gateway, hãy đặt tên tùy thích sau đó nhấn vào Create internet gateway rồi đợi nó được tạo Sau khi Internet gateway được tạo xong hãy vào phần Actions và bấm vào Attach to VPC để gán nó vào VPC đã được tạo ở phần trước Tạo NAT Gateway Tạo NAT Gateway đặt tại Public Subnet 1 Gán Elastic IP để có địa chỉ tỉnh ra Internet "},{"uri":"https://EroEroz.github.io/vi/5-workshop/5.3-network/5.3.3-routing/","title":"Cấu hình Route Table","tags":[],"description":"","content":"Tạo Route Table Ấn vào phần Route tables trong VPC dashboard\nTạo 2 Route Table, Public với Private\nPublic Route Table: Đối với Public Route Table, trong phần Routes ấn vào Edit routes Trỏ 0.0.0.0/0 về Internet Gateway Và trong phần Subnet associations, gán cho cả hai Public Subnets Private Route Table: Đối với Public Route Table, chúng ta sẽ trỏ 0.0.0.0/0 về NAT Gateway Và trong phần Subnet associations, gán cho cả hai Private Subnets Việc tách biệt Route Table đảm bảo rằng các Database trong Private Subnet không bao giờ bị lộ trực tiếp ra Internet.\n"},{"uri":"https://EroEroz.github.io/vi/4-eventparticipated/4.2-event2/","title":"Event 2","tags":[],"description":"","content":"Bài thu hoạch “Data Science on AWS Workshop” Mục Đích Của Sự Kiện Trải nghiệm thực tế các dịch vụ AI/ML của AWS. Tìm hiểu quy trình chuẩn bị dữ liệu và xây dựng mô hình Machine Learning mà không cần viết quá nhiều code (Low-code/No-code). Nội Dung Nổi Bật Khám phá AI Services (AI Services Exploration) Amazon Textract: Dịch vụ trích xuất văn bản và dữ liệu từ các văn bản quét (OCR) một cách thông minh. Amazon Polly: Dịch vụ chuyển đổi văn bản thành giọng nói (Text-to-Speech) với ngữ điệu tự nhiên. Chuẩn bị dữ liệu \u0026amp; Xây dựng mô hình (Data Prep \u0026amp; Modeling) Amazon SageMaker Canvas: Công cụ No-code giúp các nhà phân tích kinh doanh (Business Analysts) tự xây dựng mô hình ML trực quan. SageMaker Processing: Xử lý và làm sạch dữ liệu quy mô lớn. SageMaker Studio: Môi trường phát triển tích hợp (IDE) toàn diện cho Machine Learning, từ xây dựng, huấn luyện đến triển khai mô hình. Những Gì Học Được Phân biệt AI vs ML: Hiểu rõ sự khác biệt giữa việc sử dụng các dịch vụ AI có sẵn (như Polly, Textract) và việc tự xây dựng mô hình ML tùy chỉnh trên SageMaker. Low-code ML: Nhận thấy xu hướng dân chủ hóa Machine Learning, giúp những người không chuyên sâu về code vẫn có thể tạo ra giá trị từ dữ liệu nhờ SageMaker Canvas. Ứng Dụng Vào Công Việc Có thể tích hợp Amazon Polly vào dự án MiniMarket để đọc thông tin sản phẩm cho người khiếm thị (Accessibility). Sử dụng Textract để tự động hóa quy trình nhập liệu hóa đơn đầu vào cho hệ thống quản lý kho. "},{"uri":"https://EroEroz.github.io/vi/5-workshop/5.4-data/5.4.2-rds/","title":"Khởi tạo Amazon RDS","tags":[],"description":"","content":" Truy cập RDS Console \u0026gt; Subnet groups \u0026gt; Create DB subnet group Name: db-private-group. Subnets: Chọn 2 AZ và chọn đúng 2 Private Subnet Vào Databases \u0026gt; Create database Engine options: Microsoft SQL Server (Express Edition) Templates: Free tier. Settings: Đặt mật khẩu Master Password (ghi nhớ để dùng sau này) Connectivity: VPC: VPC mà bạn đã tạo cho Web Subnet group: db-private-group Public access: No VPC security group: Chọn Security group mà bạn tạo cho database Bấm Create database "},{"uri":"https://EroEroz.github.io/vi/5-workshop/5.5-app/5.5.2-beanstalk-setup/","title":"Khởi tạo Elastic Beanstalk","tags":[],"description":"","content":"Chúng ta sẽ tạo môi trường chạy ứng dụng\nTruy cập Elastic Beanstalk \u0026gt; Create application App Name: MiniMarket-App Platform: Docker (Amazon Linux 2023) Application code: Chọn Sample application (Để test hạ tầng trước) Cấu hình Mạng (Networking) - Cực kỳ quan trọng: VPC: Chọn VPC mà bạn đã tạo cho MiniMarket Instance settings: Public IP address: Bỏ tích Subnets: Tích chọn 2 Private Subnet EC2 security groups: Chọn sg-web-app Capacity: Environment type: Chọn Load balanced Load balancer network settings: Visibility: Public Subnets: Tích chọn 2 Public Subnet Bấm Create. Hệ thống sẽ mất khoảng 5-7 phút để khởi tạo "},{"uri":"https://EroEroz.github.io/vi/5-workshop/5.6-cicd/5.6.2-codepipeline/","title":"Thiết lập CodePipeline","tags":[],"description":"","content":" Truy cập CodePipeline \u0026gt; Create pipeline\nCategory: Chọn Buid custom pipeline\nSettings: Chọn New service role\nSource Stage: Chọn GitHub (via GitHub App) \u0026gt; Connect to GitHub \u0026gt; Chọn Repo và nhánh mà bạn deploy lên cloud\nBuild Stage: Chọn AWS CodeBuild \u0026gt; Chọn project MiniMarket-Build vừa tạo\nTest Stage: Bấm Skip test stage\nDeploy Stage:\nProvider: AWS Elastic Beanstalk Application name: MiniMarket-App Environment name: Chọn môi trường đang chạy Bấm Create pipeline\nNếu bước Deploy bị lỗi Permission, hãy vào IAM Role của CodePipeline và cấp quyền AdministratorAccess-AWSElasticBeanstalk\n"},{"uri":"https://EroEroz.github.io/vi/5-workshop/5.7-security/5.7.2-waf/","title":"Thiết lập Tường lửa (WAF)","tags":[],"description":"","content":" Truy cập WAF \u0026amp; Shield \u0026gt; Protection packs (webs ACLs) \u0026gt; Create protection pack (web ACL) App category: E-commerce \u0026amp; transaction platforms App focus: Both API and web Add resources \u0026gt; Add CloudFront or Amplify resources \u0026gt; Chọn CloudFront distribution đã tạo ở phần trước Choose initial protections \u0026gt; Build your own pack from all of the protections AWS WAF offers \u0026gt; AWS-managed rule group:\nThêm Core rule set (Chặn bot, IP xấu) Thêm SQL database (Chặn SQL Injection) Kiểm thử: Truy cập URL: https://[domain]/?id=1 OR 1=1. Nếu nhận lỗi 403 Forbidden, WAF đã hoạt động.\n"},{"uri":"https://EroEroz.github.io/vi/1-worklog/1.10-week10/","title":"Worklog tuần 10","tags":[],"description":"","content":"Mục tiêu tuần 10: Hoàn thiện và hoàn thành đề xuất dự án nhóm bằng cách viết các phần còn lại \u0026ldquo;Expected Outcomes\u0026rdquo; và \u0026ldquo;Executive Summary\u0026rdquo;.\nThực hiện rà soát lỗi cuối cùng cho bản đề xuất để đảm bảo chất lượng và sửa các lỗi nhỏ.\nBắt đầu khóa học tiếp theo \u0026ldquo;Natural Language Processing with Sequence Models\u0026rdquo;.\nCác nhiệm vụ thực hiện trong tuần này: Thứ Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Hoàn thành đề xuất dự án: + Viết phần \u0026ldquo;Expected Outcomes\u0026rdquo; + Viết phần \u0026ldquo;Executive Summary\u0026rdquo; - Bắt đầu Tuần 1 của khóa học Coursera \u0026ldquo;Natural Language Processing with Sequence Models\u0026rdquo; 10/11/2025 10/11/2025 https://www.coursera.org/learn/sequence-models-in-nlp/home/module/1 3 - Hoàn thành Tuần 1 của khóa học Coursera \u0026ldquo;Natural Language Processing with Sequence Models\u0026rdquo; - Đọc và thực hiện các điều chỉnh nhỏ cho đề xuất dự án 11/11/2025 11/11/2025 https://www.coursera.org/learn/sequence-models-in-nlp/home/module/1 4 - Bắt đầu Tuần 2 của khóa học Coursera \u0026ldquo;Natural Language Processing with Sequence Models\u0026rdquo;: + Chủ đề: LSTMs and Named Entity Recognition - Học về RNNs, Vanishing Gradients, LSTMs, và NER (Training, Data Processing, Accuracy) - Hoàn thành Practice Assignment. 12/11/2025 12/11/2025 https://www.coursera.org/learn/sequence-models-in-nlp/home/module/2 5 - Tiếp tục Tuần 2 và Bắt đầu Tuần 3 của khóa học Coursera \u0026ldquo;Natural Language Processing with Sequence Models\u0026rdquo;: + Hoàn thành Tuần 2: - Hoàn thành bài tập lập trình \u0026ldquo;Named Entity Recognition (NER)\u0026rdquo;. + Bắt đầu Tuần 3: - Chủ đề: Siamese Networks - Đã học: - Siamese Networks architecture, cost function - Triplets (bao gồm hard triplets), computing cost - One-shot learning, và training/testing - Hoàn thành Practice Assignment 13/11/2025 13/11/2025 https://www.coursera.org/learn/sequence-models-in-nlp/programming/hDP4K/named-entity-recognition-ner https://www.coursera.org/learn/sequence-models-in-nlp/home/module/3 6 - Hoàn thành khóa học \u0026ldquo;Natural Language Processing with Sequence Models\u0026rdquo;: + Hoàn thành bài tập lập trình cuối cùng (Tuần 3): \u0026ldquo;Question\nDuplicates\u0026rdquo; - Bắt đầu khóa học \u0026ldquo;Natural Language Processing with Attention Models\u0026rdquo;\n(Tuần 1): + Chủ đề: Neural Machine Translation - Học: - Seq2seq, Seq2seq with attention - Queries, Keys, Values, và Attention - Setup for Machine Translation, Teacher forcing - NMT Model with attention, và Bleu Score - Hoàn thành Lab: - Basic attention - Scaled Dot-Product Attention 14/11/2025 14/11/2025 https://www.coursera.org/learn/sequence-models-in-nlp/programming/jjKpq/question-duplicates https://www.coursera.org/learn/attention-models-in-nlp/home/module/1 Kết quả đạt được tuần 10: Hoàn thiện Đề xuất Dự án: Đã hoàn thành đề xuất dự án, bao gồm \u0026ldquo;Executive Summary\u0026rdquo; và \u0026ldquo;Expected Outcomes,\u0026rdquo; và thực hiện kiểm tra lỗi.\nHoàn thành Khóa học \u0026ldquo;Sequence Models\u0026rdquo;: Thể hiện tốc độ học tập vượt trội bằng cách hoàn thành khóa học \u0026ldquo;Natural Language Processing with Sequence Models\u0026rdquo; trong một tuần.\nBắt đầu Khóa học \u0026ldquo;Attention Models\u0026rdquo;: Ngay lập tức bắt đầu khóa học tiếp theo, \u0026ldquo;Natural Language Processing with Attention Models,\u0026rdquo; và đạt được tiến bộ đáng kể, bao gồm các chủ đề Seq2seq, Attention, QKV, và hoàn thành hai bài lab (Basic Attention và Scaled Dot-Product Attention).\n"},{"uri":"https://EroEroz.github.io/vi/1-worklog/1.11-week11/","title":"Worklog tuần 11","tags":[],"description":"","content":"Mục tiêu tuần 11: Kiểm tra và đồng bộ hóa codebase backend mới nhất để triển khai. Chuẩn bị cấu hình ứng dụng (Biến môi trường) cho production. Soạn thảo các script build và file cấu hình cho các dịch vụ AWS. Hoàn thiện cấu trúc dự án cho việc di chuyển lên cloud sắp tới. Các nhiệm vụ thực hiện trong tuần này: Thứ Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Tham dự workshop \u0026ldquo;DevOps on AWS\u0026rdquo; + Buổi sáng (CI/CD \u0026amp; IaC): - Học về Tư duy DevOps và các chỉ số (DORA, MTTR) - Tìm hiểu sâu về AWS Code Suite (CodeCommit, CodeBuild, CodeDeploy, CodePipeline) - Khám phá Infrastructure as Code (IaC) sử dụng CloudFormation và CDK + Buổi chiều (Containers \u0026amp; Observability): - Bao gồm các kiến thức cơ bản về Docker và điều phối Amazon ECR/ECS/EKS - Học các best practice về Monitoring \u0026amp; Observability sử dụng CloudWatch và AWS X-Ray 17/11/2025 17/11/2025 3 - Chuẩn bị Codebase \u0026amp; Cấu hình (Thực hiện sau workshop) + Đồng bộ với team backend để lấy nhánh release ổn định + Làm sạch appsettings.json và mapped Biến môi trường cho cloud 18/11/2025 18/11/2025 4 - Soạn thảo các lệnh buildspec.yml cho pipeline CI/CD sắp tới 19/11/2025 19/11/2025 5 - Xóa các file không sử dụng và log debug khỏi thư mục dự án 20/11/2025 20/11/2025 6 - Xem lại danh sách kiểm tra triển khai cho tuần tới + Xác nhận với nhóm rằng sẽ không có thay đổi code nào được thực hiện trước thứ Hai 21/11/2025 21/11/2025 Kết quả đạt được tuần 11: Chuẩn bị thành công cấu hình ứng dụng cho môi trường production. Dọn dẹp cấu trúc dự án để đảm bảo triển khai suôn sẻ. Xác nhận dự án đã sẵn sàng cho việc di chuyển lên cloud vào tuần 12. "},{"uri":"https://EroEroz.github.io/vi/1-worklog/1.12-week12/","title":"Worklog tuần 12","tags":[],"description":"","content":"Mục tiêu tuần 12: Triển khai và kiểm tra độ ổn định của dự án trên AWS Cloud. Triển khai tự động hóa CI/CD sử dụng AWS CodePipeline. Tối ưu hóa phân phối static assets sử dụng S3 và CloudFront. Distributed caching sử dụng Amazon ElastiCache (Redis). Bắt đầu đào tạo về AWS Cloud Architecture. Các nhiệm vụ thực hiện trong tuần này: Thứ Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Xem xét và merge các thay đổi code nhóm mới nhất để đảm bảo tính nhất quán + Refactor các file cấu hình cục bộ (appsettings) để chuẩn bị cho việc di chuyển lên AWS 24/11/2025 24/11/2025 3 - Test deploy code dự án lên AWS Cloud để xác minh độ ổn định + Xác minh các chức năng: thêm vào giỏ hàng và thanh toán + Cấu hình dịch vụ để đảm bảo tương thích với code nhóm - Đăng ký khóa học AWS Cloud Solutions Architect trên Coursera + Bắt đầu Khóa 1: AWS Cloud Technical Essentials - Hoàn thành tài liệu giới thiệu Tuần 1: AWS Overview and Security - Bao gồm What is AWS? và AWS Global Infrastructure (Video \u0026amp; Bài đọc 1.3) 25/11/2025 25/11/2025 4 - Cấu hình AWS CodePipeline cho việc triển khai tự động + Thiết lập các dịch vụ CodeBuild và CodeDeploy - Cấu hình tích hợp GitHub: push code sẽ kích hoạt triển khai tự động lên AWS Cloud 26/11/2025 26/11/2025 5 - Khởi tạo S3 Bucket và di chuyển static assets (hình ảnh) + Cấu hình CloudFront (CDN) để phục vụ nội dung từ S3 + Triển khai các kiểm soát bảo mật (OAC và Bucket Policies) 27/11/2025 27/11/2025 6 - Triển khai cluster Amazon ElastiCache (Redis) + Cấu hình ứng dụng .NET Core sử dụng Redis để tích hợp Session Storage 28/11/2025 28/11/2025 Kết quả đạt được tuần 12: Đã thành công triển khai dự án trên AWS Cloud. Thiết lập pipeline CI/CD sử dụng CodePipeline, CodeBuild, và CodeDeploy. Tích hợp thành công S3 và CloudFront để lưu trữ và phân phối static assets. Triển khai Amazon ElastiCache để xử lý distributed session. Bắt đầu đào tạo AWS: Hoàn thành các module giới thiệu về AWS Global Infrastructure. "},{"uri":"https://EroEroz.github.io/vi/3-blogstranslated/","title":"Các bài blogs đã dịch","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTại đây sẽ là phần liệt kê, giới thiệu các blogs mà các bạn đã dịch. Ví dụ:\nBlog 1 - Getting started with healthcare data lakes: Using microservices Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 2 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 3 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 4 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 5 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 6 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\n"},{"uri":"https://EroEroz.github.io/vi/5-workshop/5.5-app/5.5.3-app-config/","title":"Cấu hình Biến môi trường","tags":[],"description":"","content":"Để ứng dụng kết nối được với Database và Redis, chúng ta không hardcode trong code mà dùng Biến môi trường\nVào Beanstalk Environment \u0026gt; Configuration \u0026gt; Updates, monitoring, and logging \u0026gt; Edit\nKéo xuống mục Environment properties\nThêm các biến sau:\nName: ConnectionStrings__DefaultConnection\nValue: Server=sql-shop-db\u0026hellip;.rds.amazonaws.com;Database=MiniMarketDB;User Id=admin;Password=PASSWORD BẠN ĐẶT;TrustServerCertificate=True; Name: ConnectionStrings__RedisConnection\nValue: webapp.redis.cache\u0026hellip;:6379 Name: VnPay__IPNUrl\nValue: https://[cloudfrontdomain].cloudfront.net/Payment/VnPayIPN Name: VnPay__ReturnUrl\nValue: https://[cloudfrontdomain].cloudfront.net/Payment/VnPayReturn Bấm Apply. Server sẽ khởi động lại để nhận cấu hình mới "},{"uri":"https://EroEroz.github.io/vi/4-eventparticipated/4.3-event3/","title":"Event 3","tags":[],"description":"","content":"Bài thu hoạch “Reinventing DevSecOps” Mục Đích Của Sự Kiện Định nghĩa lại quy trình phát triển phần mềm an toàn (DevSecOps Lifecycle) từ khâu lập kế hoạch đến vận hành. Giới thiệu bộ công cụ (Toolchain) toàn diện để tích hợp bảo mật vào từng giai đoạn của CI/CD. Xây dựng tư duy \u0026ldquo;Security-First\u0026rdquo; cho đội ngũ phát triển và vận hành. Đơn Vị Tổ Chức CMC Global Nội Dung Nổi Bật 1. Vòng Đời DevSecOps (The DevSecOps Lifecycle) Quy trình được chia thành 7 giai đoạn khép kín, đảm bảo bảo mật không phải là \u0026ldquo;nút thắt cổ chai\u0026rdquo; mà là một phần của dòng chảy:\nPLAN (Lập kế hoạch): Xác định yêu cầu bảo mật ngay từ đầu (Security Requirements). Thống nhất mục tiêu giữa Dev, Sec và Ops. Xây dựng lộ trình bảo mật (Security Roadmap) bám sát mục tiêu dự án. CODE (Viết mã): Áp dụng các tiêu chuẩn Clean Code và Secure Coding. Sử dụng SAST (Static Application Security Testing) ngay trên IDE để phát hiện lỗi sớm. Hình thành tư duy \u0026ldquo;Security-first\u0026rdquo; cho Developer. BUILD (Xây dựng): Tự động kiểm tra bảo mật trong CI/CD Pipeline. Quét các thư viện phụ thuộc (Dependency Scan) và mã nhị phân (Binary Scan). Đảm bảo bản build an toàn và nhất quán (Immutable Artifacts). TEST (Kiểm thử): Chạy quét lỗ hổng (Vulnerability Scan) và DAST (Dynamic Application Security Testing). Thực hiện Penetration Test (Kiểm thử xâm nhập). DEPLOY (Triển khai): Kiểm tra cấu hình và IaC (Infrastructure as Code) trước khi deploy. Giám sát cấu hình Runtime. OPERATE (Vận hành): Tự động vá lỗi (Auto-patching) và cập nhật bảo mật liên tục. Có quy trình phản ứng sự cố (Incident Response). MONITOR (Giám sát): Theo dõi liên tục các mối đe dọa (Threats). Sử dụng Real-time Analytics và các công cụ cảnh báo (Alerting). 2. Hệ Sinh Thái Công Cụ (DevSecOps Toolchain Overview) Một hệ thống DevSecOps mạnh mẽ cần sự phối hợp của nhiều công cụ chuyên biệt:\nPre-commit \u0026amp; Code Quality: SonarQube, Codacy: Kiểm tra chất lượng code. GitLeaks: Quét và ngăn chặn việc lộ Secret/Key trong code trước khi commit. Dependency \u0026amp; SBOM Scanning: Syft, Grype, Dependency-Track: Quản lý các gói phần mềm và phát hiện lỗ hổng trong thư viện bên thứ 3. IaC \u0026amp; Policy-as-Code: Checkov, Tfsec: Quét lỗi bảo mật trong file Terraform/Kubernetes. OPA Gatekeeper, Kyverno: Thực thi chính sách tuân thủ tự động trên Cluster. SAST / DAST \u0026amp; Security Tests: Trivy, Checkmarx: Phát hiện lỗ hổng toàn diện từ Code đến Runtime. CI/CD Integration: Jenkins, GitHub Actions, GitLab CI, ArgoCD: Nền tảng để tự động hóa toàn bộ quy trình trên. Monitoring \u0026amp; Logging: Prometheus, Grafana, Loki: Giám sát sức khỏe hệ thống (Observability). Alerting \u0026amp; Governance: Slack, Email, AI Anomaly Detection: Cảnh báo tức thì khi có sự cố. Những Gì Học Được Tư Duy \u0026ldquo;Shift Left\u0026rdquo; Bảo mật không nên để đến cuối mới làm (Giai đoạn Test/Operate) mà phải đưa sang trái (Shift Left) - tức là làm ngay từ khâu Plan và Code. Việc phát hiện lỗi sớm giúp tiết kiệm chi phí sửa chữa gấp nhiều lần. Tầm Quan Trọng Của Automation Không thể làm bảo mật thủ công trong thời đại Cloud. Cần tích hợp các công cụ quét (Scan) vào Pipeline để chặn các bản build lỗi một cách tự động. Quản Lý Rủi Ro Chuỗi Cung Ứng (Supply Chain Security) Thông qua việc quét Dependency (SBOM), ta có thể ngăn chặn các cuộc tấn công vào thư viện thứ 3 (tương tự vụ Log4j). Ứng Dụng Vào Công Việc Tích hợp GitLeaks: Cài đặt ngay pre-commit hook để ngăn chặn việc vô tình push AWS Access Key lên GitHub. Triển khai SonarQube: Tích hợp vào quy trình CI hiện tại để đo lường nợ kỹ thuật và lỗ hổng bảo mật. Áp dụng IaC Scanning: Sử dụng Checkov để quét các file CloudFormation/Terraform trước khi apply hạ tầng lên AWS. Monitoring: Thiết lập Dashboard Grafana để theo dõi trạng thái ứng dụng real-time. Trải nghiệm trong event Mặc dù chỉ tham gia qua hình thức theo dõi tài liệu, nhưng nội dung của CMC Global mang lại cái nhìn rất hệ thống về DevSecOps.\nSự rõ ràng trong quy trình Slide về DevSecOps Lifecycle giúp mình hình dung rõ ràng bức tranh toàn cảnh, biết được ở mỗi giai đoạn cần làm gì thay vì chỉ tập trung vào viết code như trước đây. Bộ công cụ thực chiến Slide Toolchain là một \u0026ldquo;kho báu\u0026rdquo; thực sự. Nó cung cấp danh sách các công cụ tiêu chuẩn ngành (Industry Standard) mà mình có thể tìm hiểu và áp dụng ngay lập tức cho dự án MiniMarket của mình (ví dụ như dùng Trivy để quét Docker Image).\nSự kiện đã nhấn mạnh rằng: Trong kỷ nguyên AI và Cloud, Bảo mật không phải là một tính năng (feature), mà là một văn hóa (culture) cần được xây dựng từ những dòng code đầu tiên.\n"},{"uri":"https://EroEroz.github.io/vi/5-workshop/5.4-data/5.4.3-elasticache/","title":"Khởi tạo ElastiCache Redis","tags":[],"description":"","content":" Truy cập ElastiCache \u0026gt; Subnet groups \u0026gt; Create subnet group Name: redis-private-group Subnets: Chọn 2 Private Subnet Vào Redis OSS caches \u0026gt; Create cache Tại màn hình Cluster settings: Engine: Chọn Redis OSS Deployment option: Chọn Node-based cluster Creation method: Chọn Cluster cache (Configure and create a new cluster) Cluster mode: Chọn Disabled (Chế độ đơn giản, 1 Shard) Tại màn hình Location:\nLocation: AWS Cloud Multi-AZ: Bỏ tích (Enable) Lưu ý: Tắt tính năng này để tiết kiệm chi phí cho môi trường Lab Auto-failover: Bỏ tích (Enable) Tại màn hình Cache settings:\nEngine version: Để mặc định (VD: 7.1) Port: 6379 Node type: Chọn dòng t3 \u0026gt; Chọn cache.t3.micro Number of replicas: Nhập 0 (Chúng ta chỉ cần 1 node chính, không cần node dự phòng) Tại màn hình Connectivity: Network type: IPv4 Subnet groups: Chọn Choose existing subnet group \u0026gt; Chọn redis-private-group vừa tạo Tại màn hình Advanced settings (Quan trọng): Encryption at rest: Enable (Mặc định) Encryption in transit: Bỏ tích (Disable) Lý do: Tắt mã hóa đường truyền giúp đơn giản hóa việc kết nối từ code .NET trong môi trường nội bộ VPC mà không cần cấu hình chứng chỉ SSL phức tạp Selected security groups: Chọn Manage \u0026gt; chọn sg-redis-cache (Bỏ chọn default) Kéo xuống cuối cùng và bấm Create 3. Lấy thông tin kết nối Quá trình khởi tạo sẽ mất khoảng 5-10 phút\nKhi trạng thái chuyển sang Available (Màu xanh) Bấm vào tên Cluster (webapp hoặc tên bạn đặt) Tại tab Overview, tìm mục Primary endpoint Copy chuỗi kết nối này (Ví dụ: webapp.xxxx.cache.amazonaws.com) Endpoint này sẽ được dùng để cấu hình biến môi trường ConnectionStrings__RedisConnection cho Elastic Beanstalk ở các bước sau.\n"},{"uri":"https://EroEroz.github.io/vi/5-workshop/5.3-network/","title":"Thiết lập Hạ tầng Mạng","tags":[],"description":"","content":"Tổng quan Trong phần này, chúng ta sẽ xây dựng nền móng mạng lưới cho ứng dụng MiniMarket. Một kiến trúc mạng an toàn là yếu tố tiên quyết để bảo vệ ứng dụng và dữ liệu\nChúng ta sẽ thiết kế một VPC gồm có:\nPublic Subnet: Dành cho các thành phần giao tiếp trực tiếp với Internet (Load Balancer, NAT Gateway). Private Subnet Dành cho các thành phần cần bảo mật (App Server, Database, Redis) Ngoài ra, chúng ta sẽ cấu hình NAT Gateway để cho phép các máy chủ ở bên trong Private Subnet có thể tải được các bản cập nhật và Docker Image từ Internet mà không bị lộ địa chỉ IP ra ngoài\nNội dung Khởi tạo VPC \u0026amp; Subnet Cấu hình Internet \u0026amp; NAT Gateway Cấu hình Route Table "},{"uri":"https://EroEroz.github.io/vi/4-eventparticipated/4.4-event4/","title":"Event 4","tags":[],"description":"","content":"Bài thu hoạch “AI/ML/GenAI on AWS” Mục Đích Của Sự Kiện Giới thiệu tổng quan về Foundation Models và nền tảng Amazon Bedrock Hướng dẫn các kỹ thuật Prompt Engineering từ cơ bản đến nâng cao Giải thích kiến trúc và quy trình hoạt động của RAG (Retrieval Augmented Generation) Giới thiệu hệ sinh thái các dịch vụ Pretrained AI của AWS và các Framework xây dựng AI Agents Danh Sách Diễn Giả Lam Tuan Kiet Danh Hoanh Hieu Nghi Dinh Le Hoang Anh Nội Dung Nổi Bật Foundation Models \u0026amp; Amazon Bedrock Foundation Models (FMs): Được huấn luyện theo phương pháp self-supervisor training, có khả năng xử lý đa nhiệm (many tasks). Amazon Bedrock: Nền tảng cung cấp quyền truy cập vào các mô hình hàng đầu như Luma, Deepseek\u0026hellip; Prompt Engineering (Kỹ thuật ra lệnh cho AI) Quy trình cơ bản: Prompt → Bedrock → Response. Các kỹ thuật chính:\nZero-Shot Prompting: Đặt câu hỏi trực tiếp mà không cần cung cấp dữ liệu mẫu. Few-Shot Prompting: Cung cấp một vài ví dụ (example frame) để mô hình học theo cấu trúc câu trả lời khi gặp câu hỏi tương tự. Chain of Thought (CoT): Hướng dẫn AI cách suy luận từng bước (step-by-step reasoning), giúp AI đưa ra câu trả lời chính xác hơn dựa trên logic đã học. Retrieval Augmented Generation (RAG) Mô hình phổ biến hiện nay (dùng nhiều trong Banking). Quy trình gồm: Retrieval → Augmentation → Generation.\nEmbeddings: Chuyển đổi ngôn ngữ con người thành Vector. Sử dụng Amazon Titan Embedding (hỗ trợ đa ngôn ngữ). RAG in Action: Chuẩn bị dữ liệu: Data source → Document chunk → Embeddings model → Vector store. Xử lý truy vấn: User input → Embeddings model → Vector → Semantic search (trong Vector store) → Context → Prompt augmentation → LLM → Response. Các Dịch Vụ Pretrained AI Khác AWS cung cấp các dịch vụ chuyên biệt với chi phí tối ưu:\nAmazon Rekognition (Computer Vision): Phân tích hình ảnh/video, nhận diện khuôn mặt, vật thể. Pricing: ~$0.0013/image. Amazon Translate: Dịch thuật văn bản thời gian thực hoặc theo lô (batch). Pricing: ~$15/million characters. Amazon Textract: Trích xuất văn bản và layout từ tài liệu (OCR). Pricing: ~$0.05/page. Amazon Transcribe: Chuyển đổi giọng nói thành văn bản (Speech-to-text), hỗ trợ streaming. Amazon Polly: Chuyển đổi văn bản thành giọng nói (Text-to-Speech), hỗ trợ Real-time TTS. Pricing: ~$4/million characters. Amazon Comprehend (NLP): Phân tích cảm xúc (Sentiment Analysis), trích xuất key phrase, phát hiện thông tin cá nhân (PII). Pricing: ~$0.0001/100 chars. Amazon Kendra: Dịch vụ tìm kiếm thông minh (Intelligent Search), hỗ trợ Natural Language Search và RAG. Amazon Lookout Family: Phát hiện bất thường (Anomalies) trong Metrics, Equipment (thiết bị) và Vision (hình ảnh). Amazon Personalize: Hệ thống gợi ý (Recommendation) cá nhân hóa cho người dùng. AI Agents \u0026amp; Frameworks Pipecat: Framework cho voice/multimodal AI agents, tối ưu cho hội thoại thời gian thực (real-time conversation assistant). Amazon Bedrock AgentCore: Frameworks hỗ trợ: Langgraph, Langchain, Strands Agents SDK. Quy trình từ Idea → Production cần chú trọng: Performance, Scalability, Security, Governance. Các thành phần cốt lõi: Runtime, Memory, Identity, Gateway, Code Interpreter, Browser tool, Observability. Những Gì Học Được Tư Duy Prompting Kỹ thuật tối ưu: Hiểu rõ sự khác biệt giữa Zero-shot, Few-shot và Chain of Thought để áp dụng cho từng độ phức tạp của bài toán. Cấu trúc hóa: Việc cung cấp ví dụ (examples) giúp kiểm soát định dạng đầu ra của mô hình tốt hơn. Kiến Trúc RAG Vector Database: Hiểu vai trò quan trọng của Vector Store và Semantic Search trong việc cung cấp ngữ cảnh (context) chính xác cho LLM. Embedding Models: Tầm quan trọng của việc chọn model embedding (như Amazon Titan) để hỗ trợ đa ngôn ngữ và độ chính xác khi tìm kiếm. Lựa Chọn Dịch Vụ (Trade-offs) Cost vs Flexibility: Biết cách cân nhắc chi phí giữa việc dùng các Pretrained Services (tính tiền theo request/char) so với việc tự build model hoặc dùng LLM tổng quát. Use case specific: Mỗi dịch vụ (Rekognition, Textract\u0026hellip;) giải quyết một bài toán cụ thể tốt hơn và rẻ hơn so với việc ép LLM làm tất cả. Ứng Dụng Vào Công Việc Triển khai RAG: Áp dụng mô hình Retrieval Augmented Generation để xây dựng hệ thống search nội bộ cho doanh nghiệp/ngân hàng. Tích hợp Pretrained Services: Sử dụng Amazon Textract và Comprehend để tự động hóa quy trình xử lý hồ sơ, giấy tờ. Xây dựng Chatbot thông minh: Kết hợp Amazon Lex/Bedrock với Pipecat framework để tạo trợ lý ảo hội thoại thời gian thực. Tối ưu hóa chi phí: Sử dụng Caching cho Amazon Polly hoặc chọn đúng tier của các dịch vụ AI để giảm thiểu chi phí vận hành. Trải nghiệm trong event Tham gia sự kiện “Generative AI with Amazon Bedrock” giúp mình hệ thống hóa lại các kiến thức về GenAI và hệ sinh thái AWS. Một số điểm nhấn:\nKiến thức thực tiễn từ chuyên gia Các diễn giả đã chia sẻ những kinh nghiệm thực tế (Real-world examples) về việc áp dụng RAG và Prompt Engineering. Hiểu sâu hơn về quy trình suy luận (reasoning) của AI thông qua Chain of Thought. Bức tranh toàn cảnh về AI Services Không chỉ dừng lại ở LLM, sự kiện cung cấp cái nhìn rộng về các dịch vụ AI chuyên biệt (Specialized AI Services) như Lookout, Kendra, Personalize\u0026hellip; giúp giải quyết các bài toán ngách hiệu quả. Sự phân tích về giá (Pricing) giúp mình có thêm dữ liệu để ra quyết định khi thiết kế giải pháp. Cập nhật xu hướng công nghệ Được giới thiệu về Agentic AI và các thành phần của Bedrock AgentCore, mở ra hướng đi mới trong việc xây dựng các ứng dụng AI có khả năng thực thi tác vụ phức tạp (Idea to Production).\nTiếp cận với Pipecat framework, giải pháp tối ưu cho voice AI agents.\nTổng kết lại, sự kiện đã cung cấp một nền tảng kiến thức vững chắc về Amazon Bedrock và các kỹ thuật GenAI, từ đó giúp mình tự tin hơn trong việc đề xuất và triển khai các giải pháp AI cho dự án.\n"},{"uri":"https://EroEroz.github.io/vi/5-workshop/5.4-data/","title":"Triển khai Tầng Dữ liệu","tags":[],"description":"","content":"Tổng quan Dữ liệu là tài sản quan trọng nhất của mọi hệ thống. Vậy nên chúng ta sẽ thiết lập tầng dữ liệu (Data Layer) cho MiniMarket với tiêu chí: Bảo mật tối đa và Hiệu năng cao\nChúng ta sẽ triển khai hai dịch vụ cốt lõi:\nAmazon RDS (Relational Database Service): Sử dụng SQL Server để lưu trữ dữ liệu nghiệp vụ (Sản phẩm, Đơn hàng, Người dùng). Database sẽ được đặt trong Private Subnet để ngăn chặn truy cập trực tiếp từ Internet Amazon ElastiCache (Redis): Sử dụng Redis làm bộ nhớ đệm (In-memory Cache) để lưu trữ Session đăng nhập và giảm tải truy vấn cho Database chính Nội dung Thiết lập Security Groups cho DB \u0026amp; Cache Khởi tạo Amazon RDS (SQL Server) Khởi tạo Amazon ElastiCache (Redis) "},{"uri":"https://EroEroz.github.io/vi/4-eventparticipated/4.5-event5/","title":"Event 5","tags":[],"description":"","content":"Bài thu hoạch “DevOps on AWS” Mục Đích Của Sự Kiện Định hướng lộ trình nghề nghiệp trong lĩnh vực DevOps và Cloud. Hiểu sâu về quy trình CI/CD và Containerization. Phân tích vai trò của Infrastructure as Code (IaC) so với ClickOps. So sánh các giải pháp Orchestration trên AWS (ECS vs EKS) và chiến lược Monitoring/Observability. Nội Dung Nổi Bật Lộ Trình DevOps Thế Hệ Mới Các vai trò liên quan: DevOps Engineer, Cloud Engineer, Platform Engineer, Site Reliability Engineer (SRE). T-shaped Skill: Mô hình phát triển kỹ năng với kiến thức rộng về nhiều mảng và chuyên sâu vào một mảng cụ thể. Lời khuyên cho người mới: Do: Bắt đầu từ nền tảng, học qua dự án thực tế, viết tài liệu, tập trung làm chủ từng kỹ năng một. Don\u0026rsquo;t: Sa lầy vào \u0026ldquo;Tutorial Hell\u0026rdquo;, copy-paste mù quáng, so sánh bản thân với người khác, bỏ cuộc sau thất bại. Continuous Integration \u0026amp; Deployment (CI/CD) CI (Continuous Integration): Quy trình tích hợp code thường xuyên vào kho lưu trữ chung. Phân biệt CD: Continuous Delivery: Tự động hóa đến bước Acceptance Test, việc deploy lên Production cần kích hoạt thủ công. Continuous Deployment: Tự động hóa hoàn toàn từ code đến Production. Infrastructure as Code (IaC) Vấn đề của ClickOps: Chậm, dễ gây lỗi con người (Human Error), thiếu nhất quán, khó cộng tác. Lợi ích của IaC: Tự động hóa, khả năng mở rộng (Scalability), khả năng tái tạo (Reproducibility), tăng cường cộng tác. AWS CloudFormation: Công cụ IaC tích hợp sẵn của AWS sử dụng JSON/YAML templates. Stack: Tập hợp các resource được quản lý chung. Drift Detection: Phát hiện sự sai lệch giữa cấu hình thực tế và template (khi có ai đó sửa tay resource). AWS CDK (Cloud Development Kit): Sử dụng ngôn ngữ lập trình (Python, TS\u0026hellip;) để định nghĩa hạ tầng. Các khái niệm: L1 (Mapping 1:1), L2, L3 Constructs. Các lệnh CLI: cdk init, cdk synth, cdk deploy, cdk diff, cdk destroy. Terraform: Công cụ mã nguồn mở, hỗ trợ Multi-cloud, sử dụng ngôn ngữ HCL, quản lý trạng thái qua State file. Container Ecosystem Docker Fundamentals: Dockerfile (định nghĩa build) → Image (bản thiết kế đóng gói) → Container (runtime). Amazon ECR: Private container registry của AWS, hỗ trợ image scanning, immutable tags và lifecycle policies. Container Orchestration: Quản lý vòng đời container (restart, scale, distribute traffic). Amazon ECS: Giải pháp native của AWS. Hỗ trợ Launch types: EC2 (quản lý server) và Fargate (Serverless - dễ dàng hơn). Amazon EKS: Dịch vụ Kubernetes được quản lý. Phù hợp cho hệ thống phức tạp, yêu cầu kinh nghiệm về K8s. Amazon App Runner: Giải pháp đơn giản nhất để deploy web app/API nhanh chóng và tiết kiệm chi phí. Monitoring \u0026amp; Observability Phân biệt: Monitoring: Theo dõi Logs, Metrics (Hệ thống đang hoạt động ra sao?). Observability: Hiểu sâu nguyên nhân sự việc (Tại sao hệ thống lại hoạt động như vậy?). Amazon CloudWatch: Thu thập Metrics (CPU, RAM, Network\u0026hellip;) và Logs theo thời gian thực. Alarms: Cảnh báo và phản ứng tự động. Dashboards: Trực quan hóa dữ liệu vận hành. AWS X-Ray: Distributed tracing cho microservices, giúp vẽ bản đồ dịch vụ (Service maps) và phân tích điểm nghẽn hiệu năng (Performance bottlenecks). Những Gì Học Được Tư Duy Hệ Thống Infrastructure Drift: Hiểu được rủi ro khi sửa đổi tài nguyên thủ công ngoài IaC và tầm quan trọng của việc dùng Drift Detection. Trade-offs: Biết cách lựa chọn công cụ IaC (CDK cho AWS-centric, Terraform cho Multi-cloud) và công cụ Orchestration (ECS cho người mới/đơn giản, EKS cho tính năng cao cấp). Kỹ Năng Vận Hành Quy trình chuẩn: Sự khác biệt cốt lõi giữa Continuous Delivery và Continuous Deployment nằm ở bước duyệt thủ công lên Production. Quản lý Container: Hiểu rõ workflow từ Dockerfile lên ECR và cách ECS/EKS điều phối container hoạt động. Ứng Dụng Vào Công Việc Chuyển đổi sang IaC: Bắt đầu viết CloudFormation hoặc CDK cho dự án hiện tại thay vì thao tác trên Console. Tối ưu Pipeline: Rà soát lại quy trình CI/CD, tích hợp thêm các bước test tự động trước khi deploy. Triển khai Observability: Tích hợp AWS X-Ray vào ứng dụng để trace request qua các microservices, kết hợp với CloudWatch Alarms để giám sát chủ động. Refactor Docker: Tối ưu hóa Dockerfile và sử dụng ECR Lifecycle Policies để quản lý dung lượng lưu trữ image. Trải nghiệm trong event Tham gia sự kiện “Next-Generation DevOps \u0026amp; Cloud Architecture” là một bước đệm quan trọng giúp mình định hình rõ ràng con đường phát triển kỹ năng DevOps.\nĐịnh hướng rõ ràng Diễn giả đã vẽ ra một roadmap rất thực tế với lời khuyên \u0026ldquo;Don\u0026rsquo;t stay in Tutorial Hell\u0026rdquo; - điều mà mình rất tâm đắc. Mô hình T-shaped skill giúp mình nhận ra không cần phải biết tất cả mọi thứ ngay lập tức mà nên tập trung chuyên sâu vào một mảng trước. Kiến thức chuyên sâu về công cụ Sự so sánh chi tiết giữa ECS và EKS giúp mình tự tin hơn trong việc lựa chọn giải pháp compute phù hợp cho dự án (với người mới bắt đầu như mình, ECS Fargate là lựa chọn tối ưu). Phần trình bày về IaC và Drift Detection đã thay đổi hoàn toàn tư duy của mình về việc quản lý hạ tầng: \u0026ldquo;Use code, not clicks\u0026rdquo;. Tầm quan trọng của Observability Mình nhận ra rằng chỉ Monitoring là chưa đủ, mà cần phải đạt được Observability thông qua các công cụ như AWS X-Ray để giải quyết triệt để các vấn đề trong hệ thống phân tán. Một số hình ảnh khi tham gia sự kiện Thêm các hình ảnh của các bạn tại đây Sự kiện này không chỉ cung cấp kiến thức kỹ thuật mà còn truyền cảm hứng về tư duy làm nghề, từ việc xây dựng văn hóa CI/CD đến việc tự động hóa mọi thứ có thể.\n"},{"uri":"https://EroEroz.github.io/vi/5-workshop/5.5-app/","title":"Triển khai Ứng dụng","tags":[],"description":"","content":"Tổng quan Sau khi đã có hạ tầng mạng và dữ liệu, bước tiếp theo là đưa mã nguồn ứng dụng .NET Core lên Cloud. Thay vì quản lý từng máy chủ ảo EC2 thủ công, chúng ta sẽ sử dụng nền tảng Platform-as-a-Service (PaaS) là AWS Elastic Beanstalk\nMục tiêu của module này:\nContainerization: Đóng gói ứng dụng MiniMarket vào Docker Container để đảm bảo môi trường chạy đồng nhất (Dev = Prod) Deployment: Triển khai Container lên Elastic Beanstalk. Hệ thống sẽ tự động cấp phát EC2, cấu hình Load Balancer và Auto Scaling Group Connectivity: Cấu hình để ứng dụng kết nối an toàn tới RDS và Redis thông qua Biến môi trường (Environment Variables) Nội dung Đóng gói ứng dụng với Docker Khởi tạo Elastic Beanstalk Environment Cấu hình kết nối Database \u0026amp; Redis "},{"uri":"https://EroEroz.github.io/vi/5-workshop/","title":"Workshop","tags":[],"description":"","content":"Triển khai ứng dụng Cloud-Native MiniMarket trên AWS Tổng quan Workshop này cung cấp hướng dẫn toàn diện về việc chuyển đổi (Re-platforming) ứng dụng thương mại điện tử MiniMarket (phát triển trên nền tảng .NET Core) từ môi trường cục bộ lên hạ tầng đám mây AWS theo kiến trúc Cloud Native.\nChúng ta sẽ không chỉ đơn thuần là thuê một máy chủ ảo (EC2) để chạy code. Thay vào đó, chúng ta sẽ xây dựng một hệ thống phân tán, có khả năng mở rộng cao (Scalable), bảo mật (Secure) và vận hành tự động (Automated) dựa trên các dịch vụ được quản lý (Managed Services).\nChúng ta sẽ thiết lập một kiến trúc Đa tầng (Multi-tier) bao gồm các thành phần cốt lõi:\nCompute: Sử dụng AWS Elastic Beanstalk kết hợp với Docker để đơn giản hóa việc triển khai và quản lý ứng dụng, hỗ trợ Auto Scaling tự động dựa trên lưu lượng truy cập. Data \u0026amp; Caching: Chuyển đổi từ SQL Server cục bộ sang Amazon RDS (đặt trong Private Subnet) để đảm bảo an toàn dữ liệu. Đồng thời, triển khai Amazon ElastiCache (Redis) để quản lý Session người dùng, đảm bảo hiệu năng cao cho ứng dụng. Networking \u0026amp; Security: Sử dụng VPC cùng với Public/Private Subnet và NAT Gateway cho kết nối ra ngoài an toàn, và bảo vệ ứng dụng trước các cuộc tấn công bằng AWS WAF kết hợp CloudFront. DevOps: Xây dựng quy trình CI/CD sử dụng AWS CodePipeline và CodeBuild, cho phép tự động hóa quy trình từ lúc commit code lên GitHub đến khi ứng dụng chạy trên môi trường Production Nội dung Tổng quan về workshop Chuẩn bị Thiết lập hạ tầng mạng (VPC, NAT, Security Groups) Triển khai tầng dữ liệu (RDS \u0026amp; Redis) Triển khai ứng dụng với Elastic Beanstalk \u0026amp; Docker Tự động hóa với CI/CD Pipeline Tối ưu hóa và Bảo mật(S3, CloudFront, WAF) Giám sát (CloudWatch) Dọn dẹp tài nguyên "},{"uri":"https://EroEroz.github.io/vi/4-eventparticipated/4.6-event6/","title":"Event 6","tags":[],"description":"","content":"Bài thu hoạch “AWS Security Governance \u0026amp; Automation” Mục Đích Của Sự Kiện Giới thiệu tầm nhìn của Cloud Club và tầm quan trọng của cộng đồng. Chia sẻ các phương pháp quản lý danh tính tập trung (Identity Management) và bảo mật tài khoản. Hướng dẫn chiến lược giám sát an ninh đa lớp (Multi-Layer Visibility). Tự động hóa quy trình phản ứng sự cố bảo mật (Automated Alerting) với EventBridge. Nội Dung Nổi Bật Quản Lý Danh Tính \u0026amp; Truy Cập (IAM \u0026amp; Governance) Single Sign-On (SSO): Cơ chế \u0026ldquo;One login, multiple systems\u0026rdquo;. Thay vì tạo nhiều IAM User lẻ tẻ, SSO cho phép quản lý danh tính tập trung, giúp người dùng chỉ cần đăng nhập một lần để truy cập nhiều tài khoản/ứng dụng AWS. Service Control Policies (SCPs): Một loại chính sách tổ chức (Organizational Policy) dùng để thiết lập \u0026ldquo;hàng rào bảo vệ\u0026rdquo; (guardrails). SCPs giới hạn quyền tối đa (maximum permissions) cho các tài khoản thành viên trong AWS Organization. Phổ thông tin xác thực (Credentials Spectrum): Long-term: Access Keys của IAM User (không hết hạn) → Rủi ro cao, cần hạn chế sử dụng. Short-term: IAM Roles, STS tokens (hết hạn sau 15 phút - 36 giờ) → Bảo mật cao hơn, là best practice. MFA (Multi-Factor Authentication): Lớp bảo mật bắt buộc phải có cho mọi tài khoản. Khả Năng Quan Sát Bảo Mật Đa Lớp (Visibility) IAM Access Analyzer: Công cụ giúp phát hiện các tài nguyên (S3, KMS, IAM Roles\u0026hellip;) đang bị chia sẻ công khai hoặc chia sẻ với tài khoản ngoài vùng tin cậy. Phân loại sự kiện (Logging): Management Events: Ai đã làm gì với tài nguyên? (VD: Tạo EC2, Xóa S3 Bucket). Data Events: Ai đã truy cập vào dữ liệu? (VD: GetObject S3, Invoke Lambda). Network Activity Events: Giám sát lưu lượng mạng VPC. Tự Động Hóa \u0026amp; Cảnh Báo (Automation) Amazon EventBridge: Trung tâm xử lý sự kiện thời gian thực (Real-time Events). Hỗ trợ Cross-account Event: Nhận sự kiện từ tài khoản con về tài khoản bảo mật trung tâm. Automated Alerting: Tự động gửi cảnh báo khi phát hiện hành vi bất thường. Detection as Code: Chuyển đổi logic phát hiện mối đe dọa thành mã (Infrastructure as Code). Sử dụng CloudTrail Lake queries để truy vấn lịch sử. Quản lý phiên bản (Version control) cho các quy tắc bảo mật. Bảo Mật Mạng (Network Security) Common Attack Vectors: Các hướng tấn công mạng phổ biến (DDoS, SQL Injection, Man-in-the-middle\u0026hellip;). AWS Layered Security: Chiến lược phòng thủ chiều sâu (Defense in Depth) - bảo vệ từ lớp ngoài (Edge), lớp mạng (VPC), đến lớp ứng dụng và dữ liệu. Những Gì Học Được Tư Duy Bảo Mật Hiện Đại Identity is the new perimeter: Trong môi trường Cloud, quản lý danh tính (IAM/SSO) quan trọng hơn cả tường lửa truyền thống. Zero Trust: Không tin tưởng bất kỳ ai, luôn xác thực (MFA) và cấp quyền tối thiểu (Least Privilege). Chiến Lược Quản Trị Shift from Long-term to Short-term: Hiểu rõ rủi ro của Access Key lâu dài và tầm quan trọng của việc chuyển sang sử dụng Temporary Credentials. Governance at Scale: Sử dụng SCPs để quản lý hàng trăm tài khoản AWS một cách đồng bộ thay vì cấu hình thủ công từng cái. Kỹ Thuật Tự Động Hóa Event-Driven Security: Thay vì rà soát log thủ công (thụ động), sử dụng EventBridge để phản ứng ngay lập tức (chủ động) khi có sự cố bảo mật xảy ra. Ứng Dụng Vào Công Việc Rà soát IAM: Kiểm tra và vô hiệu hóa các IAM Access Keys cũ, bắt buộc bật MFA cho toàn bộ team. Triển khai Access Analyzer: Kích hoạt ngay để quét xem có S3 bucket nào đang public nhầm không. Thiết lập cảnh báo: Tạo rule EventBridge đơn giản để bắn thông báo về Slack/Email khi có ai đó đăng nhập bằng tài khoản Root hoặc thay đổi Security Group. Học về CloudTrail: Cấu hình CloudTrail để ghi lại cả Management và Data events cho các tài nguyên quan trọng. Trải nghiệm trong event Sự kiện thứ 3 mang đến một góc nhìn rất sâu sắc về khía cạnh Security \u0026amp; Governance - mảng thường bị xem nhẹ trong quá trình phát triển nhưng lại sống còn đối với doanh nghiệp.\nNhận thức về rủi ro Phần trình bày về Credentials Spectrum giúp tôi giật mình nhận ra thói quen sử dụng IAM User với Long-term keys nguy hiểm như thế nào. Việc chuyển dịch sang Short-term credentials là điều bắt buộc. Sức mạnh của tự động hóa Tôi rất ấn tượng với khái niệm \u0026ldquo;Detection as Code\u0026rdquo;. Việc quản lý các quy tắc bảo mật như quản lý source code giúp quy trình vận hành trở nên minh bạch và dễ kiểm soát hơn. Demo về EventBridge cho thấy khả năng phản ứng thời gian thực tuyệt vời, giúp giảm thiểu thời gian kẻ tấn công có thể gây hại trong hệ thống. Tư duy phòng thủ nhiều lớp Hiểu rõ hơn về AWS Layered Security, bảo mật không chỉ là một cánh cửa mà là nhiều lớp rào chắn phối hợp với nhau từ Network đến Identity.\nSự kiện này đã thay đổi tư duy của tôi từ \u0026ldquo;Làm cho chạy được\u0026rdquo; sang \u0026ldquo;Làm cho an toàn và tuân thủ chuẩn\u0026rdquo;. Bảo mật không phải là rào cản, mà là nền móng để phát triển bền vững.\n"},{"uri":"https://EroEroz.github.io/vi/6-self-evaluation/","title":"Tự đánh giá","tags":[],"description":"","content":"Kỳ thực tập của mình tại Công ty TNHH Amazon Web Services Việt Nam từ ngày 12/08/2025 đến 12/11/2025 là một giai đoạn mang tính bước ngoặt, nơi mình đã áp dụng kiến thức lý thuyết để xây dựng các hệ thống đám mây chuẩn thương mại có khả năng mở rộng.\nTrách nhiệm chính của mình bao gồm thiết kế Kiến trúc Giải pháp dựa trên AWS Well-Architected Framework và thiết lập Vận hành Tự động (Automated Operations - CI/CD). Thông qua quá trình này, mình đã nhanh chóng trưởng thành và phát triển các kỹ năng về Kỹ thuật Đám mây (Cloud Engineering), tư duy phản biện và viết báo cáo kỹ thuật trong môi trường doanh nghiệp.\nĐể nhìn nhận khách quan về kỳ thực tập, mình xin tự đánh giá bản thân dựa trên các tiêu chí sau:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ✅ ☐ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ✅ ☐ ☐ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ☐ ✅ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ✅ ☐ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ✅ ☐ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Cần cải thiện Đào sâu kiến thức về xử lý sự cố trên Cloud \u0026amp; tối ưu hóa hệ thống. Cải thiện khả năng diễn giải và trình bày kiến trúc hệ thống cho người khác. "},{"uri":"https://EroEroz.github.io/vi/5-workshop/5.6-cicd/","title":"Tự động hóa CI/CD","tags":[],"description":"","content":"Tổng quan Trong môi trường Cloud Native, việc triển khai thủ công (Manual Deployment) là rủi ro và tốn thời gian. Module này sẽ hướng dẫn bạn xây dựng một quy trình CI/CD (Continuous Integration / Continuous Deployment) hoàn toàn tự động\nQuy trình hoạt động như sau:\nSource: Developer đẩy code (Push) lên GitHub Build: AWS CodePipeline phát hiện thay đổi và kích hoạt AWS CodeBuild. CodeBuild sẽ đóng gói Docker Image và đẩy lên kho chứa Amazon ECR Deploy: Pipeline tự động ra lệnh cho Elastic Beanstalk cập nhật phiên bản mới nhất từ ECR mà không gây gián đoạn dịch vụ Nội dung Tạo Build Project với AWS CodeBuild Thiết lập AWS CodePipeline "},{"uri":"https://EroEroz.github.io/vi/4-eventparticipated/","title":"Các sự kiện đã tham gia","tags":[],"description":"","content":"Trong quá trình thực tập, em đã tham gia 6 sự kiện. Mỗi sự kiện là một trải nghiệm đáng nhớ, mang lại những kiến thức mới mẻ, thú vị và bổ ích, cùng với những món quà và khoảnh khắc tuyệt vời.\nEvent 1 Tên sự kiện: AWS Cloud Day 2025\nThời gian: 9:00 ngày 18 tháng 09 năm 2025\nĐịa điểm: Tầng 26, Tòa nhà Bitexco Financial Tower, Số 02 Hải Triều, Phường Sài Gòn, TP. Hồ Chí Minh\nVai trò: Người tham dự\nEvent 2 Tên sự kiện: Data Science on AWS Workshop\nThời gian: 9:30 ngày 16 tháng 10 năm 2025\nĐịa điểm: Hall Academic – Đại học FPT\nVai trò: Người tham dự\nEvent 3 Tên sự kiện: Reinventing DevSecOps with AWS Generative AI\nThời gian: 19:30 ngày 16 tháng 10 năm 2025\nĐịa điểm: Trực tuyến qua Microsoft Teams\nVai trò: Người tham dự\nEvent 4 Tên sự kiện: AI/ML/GenAI on AWS\nThời gian: 8:00 ngày 15 tháng 11 năm 2025\nĐịa điểm: Tầng 26, Tòa nhà Bitexco Financial Tower, Số 02 Hải Triều, Phường Sài Gòn, TP. Hồ Chí Minh\nVai trò: Người tham dự\nEvent 5 Tên sự kiện: DevOps on AWS\nThời gian: 8:30 ngày 17 tháng 11 năm 2025\nĐịa điểm: Tầng 26, Tòa nhà Bitexco Financial Tower, Số 02 Hải Triều, Phường Sài Gòn, TP. Hồ Chí Minh\nVai trò: Người tham dự\nEvent 6 Tên sự kiện: AWS Well-Architected Security Pillar\nThời gian: 8:30 ngày 29 tháng 11 năm 2025\nĐịa điểm: Tầng 26, Tòa nhà Bitexco Financial Tower, Số 02 Hải Triều, Phường Sài Gòn, TP. Hồ Chí Minh\nVai trò: Người tham dự\n"},{"uri":"https://EroEroz.github.io/vi/7-feedback/","title":"Chia sẻ, đóng góp ý kiến","tags":[],"description":"","content":"Đánh giá chung 1. Môi trường làm việc\nMôi trường làm việc rất thân thiện và cởi mở. Các thành viên trong FCJ luôn sẵn sàng hỗ trợ khi mình gặp khó khăn, kể cả ngoài giờ làm việc. Không gian làm việc gọn gàng, thoải mái, giúp mình tập trung tốt hơn.\n2. Sự hỗ trợ của mentor / team admin\nTeam admin hỗ trợ hướng dẫn tư duy giải quyết vấn đề, và tạo điều kiện để mình làm việc thuận lợi.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nCông việc được giao phù hợp với kiến thức mình được phổ cập, cũng như được tiếp cận với các công nghệ Cloud hiện đại sát với nhu cầu doanh nghiệp. Nhờ vậy nên mình cũng đã được học thêm nhiều kỹ năng thực tế.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, mình học được nhiều kỹ năng mới như sử dụng công cụ quản lý dự án, kỹ năng làm việc nhóm, và cả cách giao tiếp chuyên nghiệp trong môi trường công ty. Mentor cũng chia sẻ nhiều kinh nghiệm thực tế giúp mình định hướng tốt hơn cho sự nghiệp.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nMọi người tôn trọng lẫn nhau, những lúc cần nghiêm túc thì sẽ nghiêm túc, cũng có những lúc vui vẻ để bầu không khí không căng thẳng.\n6. Chính sách / phúc lợi cho thực tập sinh\nCông ty tạo điều kiện cho thực tập sinh tham gia event để có thêm kiến thức mới để hoàn thiện project, cũng như có thể áp dụng cho sau này.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập? Được tạo điều kiện tham gia các buổi workshop, events để học hỏi thêm kiến thức. Điều bạn nghĩ công ty cần cải thiện cho các thực tập sinh sau? Tăng cường thời gian làm việc trực tiếp để việc trao đổi kỹ thuật hiệu quả hơn. Nếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao? Nếu bạn bè muốn có thêm nhiều kiến thức mới thì mình sẽ gợi ý cho họ nên thực tập ở đây. Đề xuất \u0026amp; mong muốn Bạn có đề xuất gì để cải thiện trải nghiệm trong kỳ thực tập? Thêm nhiều buổi workshop để học hỏi thêm. Bạn có muốn tiếp tục chương trình này trong tương lai? Có. Góp ý khác (tự do chia sẻ): "},{"uri":"https://EroEroz.github.io/vi/5-workshop/5.7-security/","title":"Tối ưu hóa &amp; Bảo mật","tags":[],"description":"","content":"Dọn dẹp tài nguyên Tổng quan Một hệ thống Production không chỉ cần \u0026ldquo;chạy được\u0026rdquo; mà còn phải \u0026ldquo;chạy nhanh\u0026rdquo; và \u0026ldquo;an toàn\u0026rdquo;. Trong phần này, chúng ta sẽ tinh chỉnh kiến trúc MiniMarket\nCác hạng mục thực hiện:\nOffloading Static Assets: Chuyển toàn bộ hình ảnh sản phẩm từ Web Server sang Amazon S3 và phân phối qua Amazon CloudFront (CDN) để tăng tốc độ tải trang toàn cầu và giảm tải cho server Security Hardening: Triển khai AWS WAF (Web Application Firewall) chặn trước CloudFront để bảo vệ ứng dụng khỏi các cuộc tấn công phổ biến như SQL Injection và XSS Nội dung Cấu hình S3 và CloudFront Thiết lập AWS WAF "},{"uri":"https://EroEroz.github.io/vi/5-workshop/5.8-monitoring/","title":"Giám sát &amp; Vận hành","tags":[],"description":"","content":"Tổng quan Một hệ thống Production không thể được coi là hoàn thiện nếu thiếu khả năng Giám sát (Monitoring) và Cảnh báo (Alerting). Bạn không thể ngồi nhìn màn hình 24/7 để kiểm tra xem Server có còn sống hay không\nTrong module này, chúng ta sẽ thiết lập cho hệ thống giám sát và cảnh báo cho MiniMarket bằng các dịch vụ quản lý vận hành của AWS:\nAmazon CloudWatch: Thu thập các chỉ số (Metrics) từ EC2, RDS, ELB Amazon SNS (Simple Notification Service): Dịch vụ gửi thông báo. Chúng ta sẽ dùng nó để gửi Email cho người quản trị khi hệ thống gặp sự cố Chúng ta sẽ thiết lập một CloudWatch Alarm để theo dõi CPU của Web Server. Nếu CPU vượt quá 70% (dấu hiệu quá tải hoặc bị tấn công), hệ thống sẽ tự động kích hoạt SNS để gửi Email cảnh báo khẩn cấp\nNội dung Thiết lập Cảnh báo CloudWatch \u0026amp; SNS "},{"uri":"https://EroEroz.github.io/vi/5-workshop/5.9-cleanup/","title":"Dọn dẹp tài nguyên","tags":[],"description":"","content":"Tổng quan Chúc mừng bạn đã thành công triển khai MiniMarket trên AWS!\nTuy nhiên, công việc của chúng ta chưa kết thúc ở đó. Bước cuối cùng và cũng là bước quan trọng nhất để bảo vệ \u0026ldquo;ví tiền\u0026rdquo; của bạn là Dọn dẹp tài nguyên\nCác dịch vụ chúng ta đã triển khai như NAT Gateway, Elastic Load Balancer, RDS, ElastiCache đều tính phí theo giờ, dù bạn có sử dụng hay không. Nếu quên xóa, hóa đơn cuối tháng có thể rất cao\nChúng ta sẽ đi qua quy trình Decommissioning hệ thống theo đúng trình tự để đảm bảo không còn tài nguyên nào bị sót lại gây phát sinh chi phí ngầm\nNội dung Quy trình xóa tài nguyên an toàn "},{"uri":"https://EroEroz.github.io/vi/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://EroEroz.github.io/vi/tags/","title":"Tags","tags":[],"description":"","content":""}]